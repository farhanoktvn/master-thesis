
@article{seidlitz_robust_2022,
	title = {Robust deep learning-based semantic organ segmentation in hyperspectral images},
	volume = {80},
	issn = {1361-8415},
	url = {https://www.sciencedirect.com/science/article/pii/S1361841522001359},
	doi = {10.1016/j.media.2022.102488},
	abstract = {Semantic image segmentation is an important prerequisite for context-awareness and autonomous robotics in surgery. The state of the art has focused on conventional RGB video data acquired during minimally invasive surgery, but full-scene semantic segmentation based on spectral imaging data and obtained during open surgery has received almost no attention to date. To address this gap in the literature, we are investigating the following research questions based on hyperspectral imaging (HSI) data of pigs acquired in an open surgery setting: (1) What is an adequate representation of HSI data for neural network-based fully automated organ segmentation, especially with respect to the spatial granularity of the data (pixels vs. superpixels vs. patches vs. full images)? (2) Is there a benefit of using HSI data compared to other modalities, namely RGB data and processed HSI data (e.g. tissue parameters like oxygenation), when performing semantic organ segmentation? According to a comprehensive validation study based on 506 HSI images from 20 pigs, annotated with a total of 19 classes, deep learning-based segmentation performance increases — consistently across modalities — with the spatial context of the input data. Unprocessed HSI data offers an advantage over RGB data or processed data from the camera provider, with the advantage increasing with decreasing size of the input to the neural network. Maximum performance (HSI applied to whole images) yielded a mean DSC of 0.90 ((standard deviation (SD)) 0.04), which is in the range of the inter-rater variability (DSC of 0.89 ((standard deviation (SD)) 0.07)). We conclude that HSI could become a powerful image modality for fully-automatic surgical scene understanding with many advantages over traditional imaging, including the ability to recover additional functional tissue information. Our code and pre-trained models are available at https://github.com/IMSY-DKFZ/htc.},
	language = {en},
	urldate = {2022-12-14},
	journal = {Medical Image Analysis},
	author = {Seidlitz, Silvia and Sellner, Jan and Odenthal, Jan and Özdemir, Berkin and Studier-Fischer, Alexander and Knödler, Samuel and Ayala, Leonardo and Adler, Tim J. and Kenngott, Hannes G. and Tizabi, Minu and Wagner, Martin and Nickel, Felix and Müller-Stich, Beat P. and Maier-Hein, Lena},
	month = aug,
	year = {2022},
	keywords = {Deep learning, Hyperspectral imaging, Open surgery, Organ segmentation, Semantic scene segmentation, Surgical data science},
	pages = {102488},
	file = {ScienceDirect Full Text PDF:/Users/farhanoktavian/Zotero/storage/3GJ53P3N/Seidlitz et al. - 2022 - Robust deep learning-based semantic organ segmenta.pdf:application/pdf;ScienceDirect Snapshot:/Users/farhanoktavian/Zotero/storage/JPSEMWD2/S1361841522001359.html:text/html},
}

@article{haj-hassan_classifications_2017,
	title = {Classifications of {Multispectral} {Colorectal} {Cancer} {Tissues} {Using} {Convolution} {Neural} {Network}},
	volume = {8},
	issn = {2153-3539},
	url = {https://www.sciencedirect.com/science/article/pii/S2153353922004059},
	doi = {10.4103/jpi.jpi_47_16},
	abstract = {Background: Colorectal cancer (CRC) is the third most common cancer among men and women. Its diagnosis in early stages, typically done through the analysis of colon biopsy images, can greatly improve the chances of a successful treatment. This paper proposes to use convolution neural networks (CNNs) to predict three tissue types related to the progression of CRC: benign hyperplasia (BH), intraepithelial neoplasia (IN), and carcinoma (Ca). Methods: Multispectral biopsy images of thirty CRC patients were retrospectively analyzed. Images of tissue samples were divided into three groups, based on their type (10 BH, 10 IN, and 10 Ca). An active contour model was used to segment image regions containing pathological tissues. Tissue samples were classified using a CNN containing convolution, max-pooling, and fully-connected layers. Available tissue samples were split into a training set, for learning the CNN parameters, and test set, for evaluating its performance. Results: An accuracy of 99.17\% was obtained from segmented image regions, outperforming existing approaches based on traditional feature extraction, and classification techniques. Conclusions: Experimental results demonstrate the effectiveness of CNN for the classification of CRC tissue types, in particular when using presegmented regions of interest.},
	language = {en},
	number = {1},
	urldate = {2022-12-18},
	journal = {Journal of Pathology Informatics},
	author = {Haj-Hassan, Hawraa and Chaddad, Ahmad and Harkouss, Youssef and Desrosiers, Christian and Toews, Matthew and Tanougast, Camel},
	month = jan,
	year = {2017},
	keywords = {Active contour segmentation, colorectal cancer, convolution neural networks, multispectral optical microscopy},
	pages = {1},
	file = {ScienceDirect Full Text PDF:/Users/farhanoktavian/Zotero/storage/9W84YNR6/Haj-Hassan et al. - 2017 - Classifications of Multispectral Colorectal Cancer.pdf:application/pdf;ScienceDirect Snapshot:/Users/farhanoktavian/Zotero/storage/B4APQGS5/S2153353922004059.html:text/html},
}

@article{frid-adar_gan-based_2018,
	title = {{GAN}-based synthetic medical image augmentation for increased {CNN} performance in liver lesion classification},
	volume = {321},
	issn = {0925-2312},
	url = {https://www.sciencedirect.com/science/article/pii/S0925231218310749},
	doi = {10.1016/j.neucom.2018.09.013},
	abstract = {Deep learning methods, and in particular convolutional neural networks (CNNs), have led to an enormous breakthrough in a wide range of computer vision tasks, primarily by using large-scale annotated datasets. However, obtaining such datasets in the medical domain remains a challenge. In this paper, we present methods for generating synthetic medical images using recently presented deep learning Generative Adversarial Networks (GANs). Furthermore, we show that generated medical images can be used for synthetic data augmentation, and improve the performance of CNN for medical image classification. Our novel method is demonstrated on a limited dataset of computed tomography (CT) images of 182 liver lesions (53 cysts, 64 metastases and 65 hemangiomas). We first exploit GAN architectures for synthesizing high quality liver lesion ROIs. Then we present a novel scheme for liver lesion classification using CNN. Finally, we train the CNN using classic data augmentation and our synthetic data augmentation and compare performance. In addition, we explore the quality of our synthesized examples using visualization and expert assessment. The classification performance using only classic data augmentation yielded 78.6\% sensitivity and 88.4\% specificity. By adding the synthetic data augmentation the results increased to 85.7\% sensitivity and 92.4\% specificity. We believe that this approach to synthetic data augmentation can generalize to other medical classification applications and thus support radiologists’ efforts to improve diagnosis.},
	language = {en},
	urldate = {2022-12-18},
	journal = {Neurocomputing},
	author = {Frid-Adar, Maayan and Diamant, Idit and Klang, Eyal and Amitai, Michal and Goldberger, Jacob and Greenspan, Hayit},
	month = dec,
	year = {2018},
	keywords = {Deep learning, Convolutional neural networks, Data augmentation, Generative adversarial network, Image synthesis, Lesion classification, Liver lesions},
	pages = {321--331},
	file = {ScienceDirect Full Text PDF:/Users/farhanoktavian/Zotero/storage/P2B8EAJS/Frid-Adar et al. - 2018 - GAN-based synthetic medical image augmentation for.pdf:application/pdf;ScienceDirect Snapshot:/Users/farhanoktavian/Zotero/storage/CTG8ZKNM/S0925231218310749.html:text/html},
}

@article{shorten_survey_2019,
	title = {A survey on {Image} {Data} {Augmentation} for {Deep} {Learning}},
	volume = {6},
	issn = {2196-1115},
	url = {https://doi.org/10.1186/s40537-019-0197-0},
	doi = {10.1186/s40537-019-0197-0},
	abstract = {Deep convolutional neural networks have performed remarkably well on many Computer Vision tasks. However, these networks are heavily reliant on big data to avoid overfitting. Overfitting refers to the phenomenon when a network learns a function with very high variance such as to perfectly model the training data. Unfortunately, many application domains do not have access to big data, such as medical image analysis. This survey focuses on Data Augmentation, a data-space solution to the problem of limited data. Data Augmentation encompasses a suite of techniques that enhance the size and quality of training datasets such that better Deep Learning models can be built using them. The image augmentation algorithms discussed in this survey include geometric transformations, color space augmentations, kernel filters, mixing images, random erasing, feature space augmentation, adversarial training, generative adversarial networks, neural style transfer, and meta-learning. The application of augmentation methods based on GANs are heavily covered in this survey. In addition to augmentation techniques, this paper will briefly discuss other characteristics of Data Augmentation such as test-time augmentation, resolution impact, final dataset size, and curriculum learning. This survey will present existing methods for Data Augmentation, promising developments, and meta-level decisions for implementing Data Augmentation. Readers will understand how Data Augmentation can improve the performance of their models and expand limited datasets to take advantage of the capabilities of big data.},
	number = {1},
	urldate = {2022-12-19},
	journal = {Journal of Big Data},
	author = {Shorten, Connor and Khoshgoftaar, Taghi M.},
	month = jul,
	year = {2019},
	keywords = {Big data, Data Augmentation, Deep Learning, GANs, Image data},
	pages = {60},
	file = {Full Text PDF:/Users/farhanoktavian/Zotero/storage/BIYKZCYW/Shorten and Khoshgoftaar - 2019 - A survey on Image Data Augmentation for Deep Learn.pdf:application/pdf;Snapshot:/Users/farhanoktavian/Zotero/storage/Q23QV2HG/s40537-019-0197-0.html:text/html},
}

@article{lu_medical_2014,
	title = {Medical hyperspectral imaging: a review},
	volume = {19},
	issn = {1083-3668, 1560-2281},
	shorttitle = {Medical hyperspectral imaging},
	url = {https://www.spiedigitallibrary.org/journals/journal-of-biomedical-optics/volume-19/issue-1/010901/Medical-hyperspectral-imaging-a-review/10.1117/1.JBO.19.1.010901.full},
	doi = {10.1117/1.JBO.19.1.010901},
	abstract = {Hyperspectral imaging (HSI) is an emerging imaging modality for medical applications, especially in disease diagnosis and image-guided surgery. HSI acquires a three-dimensional dataset called hypercube, with two spatial dimensions and one spectral dimension. Spatially resolved spectral imaging obtained by HSI provides diagnostic information about the tissue physiology, morphology, and composition. This review paper presents an overview of the literature on medical hyperspectral imaging technology and its applications. The aim of the survey is threefold: an introduction for those new to the field, an overview for those working in the field, and a reference for those searching for literature on a specific application.},
	number = {1},
	urldate = {2022-12-19},
	journal = {Journal of Biomedical Optics},
	author = {Lu, Guolan and Fei, Baowei},
	month = jan,
	year = {2014},
	note = {Publisher: SPIE},
	pages = {010901},
	file = {Full Text PDF:/Users/farhanoktavian/Zotero/storage/FJW4Y8DM/Lu and Fei - 2014 - Medical hyperspectral imaging a review.pdf:application/pdf},
}

@article{zhi_classification_2007,
	title = {Classification of hyperspectral medical tongue images for tongue diagnosis},
	volume = {31},
	issn = {0895-6111},
	url = {https://www.sciencedirect.com/science/article/pii/S0895611107001243},
	doi = {10.1016/j.compmedimag.2007.07.008},
	abstract = {Human tongue is one of the important organs of the body, which carries abound of information of the health status. The images of the human tongue that are used in computerized tongue diagnosis of traditional Chinese medicine (TCM) are all RGB color images captured with color CCD cameras currently. However, this conversional method impedes the accurate analysis on the subjects of tongue surface because of the influence of illumination and tongue pose. To address this problem, this paper presents a novel approach to analyze the tongue surface information based on hyperspectral medical tongue images with support vector machines. The experimental results based on chronic Cholecystitis patients and healthy volunteers illustrate its effectiveness.},
	language = {en},
	number = {8},
	urldate = {2022-12-19},
	journal = {Computerized Medical Imaging and Graphics},
	author = {Zhi, Liu and Zhang, David and Yan, Jing-qi and Li, Qing-Li and Tang, Qun-lin},
	month = dec,
	year = {2007},
	keywords = {Classification, Hyperspectral tongue medical images, Support vector machines (SVM)},
	pages = {672--678},
	file = {ScienceDirect Full Text PDF:/Users/farhanoktavian/Zotero/storage/JC3V9JYX/Zhi et al. - 2007 - Classification of hyperspectral medical tongue ima.pdf:application/pdf;ScienceDirect Snapshot:/Users/farhanoktavian/Zotero/storage/UVK677E4/S0895611107001243.html:text/html},
}

@misc{ronneberger_u-net_2015,
	title = {U-{Net}: {Convolutional} {Networks} for {Biomedical} {Image} {Segmentation}},
	shorttitle = {U-{Net}},
	url = {http://arxiv.org/abs/1505.04597},
	doi = {10.48550/arXiv.1505.04597},
	abstract = {There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net .},
	urldate = {2022-12-19},
	publisher = {arXiv},
	author = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
	month = may,
	year = {2015},
	note = {arXiv:1505.04597 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:/Users/farhanoktavian/Zotero/storage/ESXN2KUI/Ronneberger et al. - 2015 - U-Net Convolutional Networks for Biomedical Image.pdf:application/pdf;arXiv.org Snapshot:/Users/farhanoktavian/Zotero/storage/UHZINJ6X/1505.html:text/html},
}

@inproceedings{fabelo_helicoid_2016,
	title = {{HELICoiD} project: a new use of hyperspectral imaging for brain cancer detection in real-time during neurosurgical operations},
	volume = {9860},
	shorttitle = {{HELICoiD} project},
	url = {https://www.spiedigitallibrary.org/conference-proceedings-of-spie/9860/986002/HELICoiD-project--a-new-use-of-hyperspectral-imaging-for/10.1117/12.2223075.full},
	doi = {10.1117/12.2223075},
	abstract = {Hyperspectral images allow obtaining large amounts of information about the surface of the scene that is captured by the sensor. Using this information and a set of complex classification algorithms is possible to determine which material or substance is located in each pixel. The HELICoiD (HypErspectraL Imaging Cancer Detection) project is a European FET project that has the goal to develop a demonstrator capable to discriminate, with high precision, between normal and tumour tissues, operating in real-time, during neurosurgical operations. This demonstrator could help the neurosurgeons in the process of brain tumour resection, avoiding the excessive extraction of normal tissue and unintentionally leaving small remnants of tumour. Such precise delimitation of the tumour boundaries will improve the results of the surgery. The HELICoiD demonstrator is composed of two hyperspectral cameras obtained from Headwall. The first one in the spectral range from 400 to 1000 nm (visible and near infrared) and the second one in the spectral range from 900 to 1700 nm (near infrared). The demonstrator also includes an illumination system that covers the spectral range from 400 nm to 2200 nm. A data processing unit is in charge of managing all the parts of the demonstrator, and a high performance platform aims to accelerate the hyperspectral image classification process. Each one of these elements is installed in a customized structure specially designed for surgical environments. Preliminary results of the classification algorithms offer high accuracy (over 95\%) in the discrimination between normal and tumour tissues.},
	urldate = {2022-12-19},
	booktitle = {Hyperspectral {Imaging} {Sensors}: {Innovative} {Applications} and {Sensor} {Standards} 2016},
	publisher = {SPIE},
	author = {Fabelo, Himar and Ortega, Samuel and Kabwama, Silvester and Callico, Gustavo M. and Bulters, Diederik and Szolna, Adam and Pineiro, Juan F. and Sarmiento, Roberto},
	month = may,
	year = {2016},
	pages = {986002},
	file = {Full Text PDF:/Users/farhanoktavian/Zotero/storage/54N4MI2R/Fabelo et al. - 2016 - HELICoiD project a new use of hyperspectral imagi.pdf:application/pdf},
}

@article{wang_image_2020,
	title = {Image segmentation evaluation: a survey of methods},
	volume = {53},
	issn = {1573-7462},
	shorttitle = {Image segmentation evaluation},
	url = {https://doi.org/10.1007/s10462-020-09830-9},
	doi = {10.1007/s10462-020-09830-9},
	abstract = {Image segmentation is a prerequisite for image processing. There are many methods for image segmentation, and as a result, a great number of methods for evaluating segmentation results have also been proposed. How to effectively evaluate the quality of image segmentation is very important. In this paper, the existing image segmentation quality evaluation methods are summarized, mainly including unsupervised methods and supervised methods. Based on hot issues, the application of metrics in natural, medical and remote sensing image evaluation is further outlined. In addition, an experimental comparison for some methods were carried out and the effectiveness of these methods was ranked. At the same time, the effectiveness of classical metrics for remote sensing and medical image evaluation is also verified.},
	language = {en},
	number = {8},
	urldate = {2022-12-24},
	journal = {Artificial Intelligence Review},
	author = {Wang, Zhaobin and Wang, E. and Zhu, Ying},
	month = dec,
	year = {2020},
	keywords = {Image segmentation, Evaluation application, Segmentation evaluation, Supervised evaluation, Unsupervised evaluation},
	pages = {5637--5674},
	file = {Full Text PDF:/Users/farhanoktavian/Zotero/storage/HUGPCDVI/Wang et al. - 2020 - Image segmentation evaluation a survey of methods.pdf:application/pdf},
}

@misc{hatamizadeh_unetr_2021,
	title = {{UNETR}: {Transformers} for {3D} {Medical} {Image} {Segmentation}},
	shorttitle = {{UNETR}},
	url = {http://arxiv.org/abs/2103.10504},
	doi = {10.48550/arXiv.2103.10504},
	abstract = {Fully Convolutional Neural Networks (FCNNs) with contracting and expanding paths have shown prominence for the majority of medical image segmentation applications since the past decade. In FCNNs, the encoder plays an integral role by learning both global and local features and contextual representations which can be utilized for semantic output prediction by the decoder. Despite their success, the locality of convolutional layers in FCNNs, limits the capability of learning long-range spatial dependencies. Inspired by the recent success of transformers for Natural Language Processing (NLP) in long-range sequence learning, we reformulate the task of volumetric (3D) medical image segmentation as a sequence-to-sequence prediction problem. We introduce a novel architecture, dubbed as UNEt TRansformers (UNETR), that utilizes a transformer as the encoder to learn sequence representations of the input volume and effectively capture the global multi-scale information, while also following the successful "U-shaped" network design for the encoder and decoder. The transformer encoder is directly connected to a decoder via skip connections at different resolutions to compute the final semantic segmentation output. We have validated the performance of our method on the Multi Atlas Labeling Beyond The Cranial Vault (BTCV) dataset for multi-organ segmentation and the Medical Segmentation Decathlon (MSD) dataset for brain tumor and spleen segmentation tasks. Our benchmarks demonstrate new state-of-the-art performance on the BTCV leaderboard. Code: https://monai.io/research/unetr},
	urldate = {2023-01-17},
	publisher = {arXiv},
	author = {Hatamizadeh, Ali and Tang, Yucheng and Nath, Vishwesh and Yang, Dong and Myronenko, Andriy and Landman, Bennett and Roth, Holger and Xu, Daguang},
	month = oct,
	year = {2021},
	note = {arXiv:2103.10504 [cs, eess]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Electrical Engineering and Systems Science - Image and Video Processing},
	file = {arXiv Fulltext PDF:/Users/farhanoktavian/Zotero/storage/F7NELHDC/Hatamizadeh et al. - 2021 - UNETR Transformers for 3D Medical Image Segmentat.pdf:application/pdf;arXiv.org Snapshot:/Users/farhanoktavian/Zotero/storage/VXN7FU99/2103.html:text/html},
}

@inproceedings{hatamizadeh_swin_2022,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Swin {UNETR}: {Swin} {Transformers} for {Semantic} {Segmentation} of {Brain} {Tumors} in {MRI} {Images}},
	isbn = {978-3-031-08999-2},
	shorttitle = {Swin {UNETR}},
	doi = {10.1007/978-3-031-08999-2_22},
	abstract = {Semantic segmentation of brain tumors is a fundamental medical image analysis task involving multiple MRI imaging modalities that can assist clinicians in diagnosing the patient and successively studying the progression of the malignant entity. In recent years, Fully Convolutional Neural Networks (FCNNs) approaches have become the de facto standard for 3D medical image segmentation. The popular “U-shaped” network architecture has achieved state-of-the-art performance benchmarks on different 2D and 3D semantic segmentation tasks and across various imaging modalities. However, due to the limited kernel size of convolution layers in FCNNs, their performance of modeling long-range information is sub-optimal, and this can lead to deficiencies in the segmentation of tumors with variable sizes. On the other hand, transformer models have demonstrated excellent capabilities in capturing such long-range information in multiple domains, including natural language processing and computer vision. Inspired by the success of vision transformers and their variants, we propose a novel segmentation model termed Swin UNEt TRansformers (Swin UNETR). Specifically, the task of 3D brain tumor semantic segmentation is reformulated as a sequence to sequence prediction problem wherein multi-modal input data is projected into a 1D sequence of embedding and used as an input to a hierarchical Swin transformer as the encoder. The swin transformer encoder extracts features at five different resolutions by utilizing shifted windows for computing self-attention and is connected to an FCNN-based decoder at each resolution via skip connections. We have participated in BraTS 2021 segmentation challenge, and our proposed model ranks among the top-performing approaches in the validation phase.},
	language = {en},
	booktitle = {Brainlesion: {Glioma}, {Multiple} {Sclerosis}, {Stroke} and {Traumatic} {Brain} {Injuries}},
	publisher = {Springer International Publishing},
	author = {Hatamizadeh, Ali and Nath, Vishwesh and Tang, Yucheng and Yang, Dong and Roth, Holger R. and Xu, Daguang},
	editor = {Crimi, Alessandro and Bakas, Spyridon},
	year = {2022},
	keywords = {Image segmentation, Brain tumor segmentation, BRATS, Swin transformer, Swin UNETR, UNETR, Vision transformer},
	pages = {272--284},
	file = {Full Text PDF:/Users/farhanoktavian/Zotero/storage/WMEX64VB/Hatamizadeh et al. - 2022 - Swin UNETR Swin Transformers for Semantic Segment.pdf:application/pdf},
}

@misc{chen_transunet_2021,
	title = {{TransUNet}: {Transformers} {Make} {Strong} {Encoders} for {Medical} {Image} {Segmentation}},
	shorttitle = {{TransUNet}},
	url = {http://arxiv.org/abs/2102.04306},
	doi = {10.48550/arXiv.2102.04306},
	abstract = {Medical image segmentation is an essential prerequisite for developing healthcare systems, especially for disease diagnosis and treatment planning. On various medical image segmentation tasks, the u-shaped architecture, also known as U-Net, has become the de-facto standard and achieved tremendous success. However, due to the intrinsic locality of convolution operations, U-Net generally demonstrates limitations in explicitly modeling long-range dependency. Transformers, designed for sequence-to-sequence prediction, have emerged as alternative architectures with innate global self-attention mechanisms, but can result in limited localization abilities due to insufficient low-level details. In this paper, we propose TransUNet, which merits both Transformers and U-Net, as a strong alternative for medical image segmentation. On one hand, the Transformer encodes tokenized image patches from a convolution neural network (CNN) feature map as the input sequence for extracting global contexts. On the other hand, the decoder upsamples the encoded features which are then combined with the high-resolution CNN feature maps to enable precise localization. We argue that Transformers can serve as strong encoders for medical image segmentation tasks, with the combination of U-Net to enhance finer details by recovering localized spatial information. TransUNet achieves superior performances to various competing methods on different medical applications including multi-organ segmentation and cardiac segmentation. Code and models are available at https://github.com/Beckschen/TransUNet.},
	urldate = {2023-01-17},
	publisher = {arXiv},
	author = {Chen, Jieneng and Lu, Yongyi and Yu, Qihang and Luo, Xiangde and Adeli, Ehsan and Wang, Yan and Lu, Le and Yuille, Alan L. and Zhou, Yuyin},
	month = feb,
	year = {2021},
	note = {arXiv:2102.04306 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:/Users/farhanoktavian/Zotero/storage/TIFCJSCC/Chen et al. - 2021 - TransUNet Transformers Make Strong Encoders for M.pdf:application/pdf;arXiv.org Snapshot:/Users/farhanoktavian/Zotero/storage/RH7CDCJP/2102.html:text/html},
}

@misc{cheng_masked-attention_2022,
	title = {Masked-attention {Mask} {Transformer} for {Universal} {Image} {Segmentation}},
	url = {http://arxiv.org/abs/2112.01527},
	doi = {10.48550/arXiv.2112.01527},
	abstract = {Image segmentation is about grouping pixels with different semantics, e.g., category or instance membership, where each choice of semantics defines a task. While only the semantics of each task differ, current research focuses on designing specialized architectures for each task. We present Masked-attention Mask Transformer (Mask2Former), a new architecture capable of addressing any image segmentation task (panoptic, instance or semantic). Its key components include masked attention, which extracts localized features by constraining cross-attention within predicted mask regions. In addition to reducing the research effort by at least three times, it outperforms the best specialized architectures by a significant margin on four popular datasets. Most notably, Mask2Former sets a new state-of-the-art for panoptic segmentation (57.8 PQ on COCO), instance segmentation (50.1 AP on COCO) and semantic segmentation (57.7 mIoU on ADE20K).},
	urldate = {2023-01-20},
	publisher = {arXiv},
	author = {Cheng, Bowen and Misra, Ishan and Schwing, Alexander G. and Kirillov, Alexander and Girdhar, Rohit},
	month = jun,
	year = {2022},
	note = {arXiv:2112.01527 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	file = {arXiv Fulltext PDF:/Users/farhanoktavian/Zotero/storage/SZ4WU8UQ/Cheng et al. - 2022 - Masked-attention Mask Transformer for Universal Im.pdf:application/pdf;arXiv.org Snapshot:/Users/farhanoktavian/Zotero/storage/CB6RAQDX/2112.html:text/html},
}

@article{chalopin_kunstliche_2022,
	title = {Künstliche {Intelligenz} und hyperspektrale {Bildgebung} zur bildgestützten {Assistenz} in der minimal-invasiven {Chirurgie}},
	volume = {93},
	issn = {2731-698X},
	url = {https://doi.org/10.1007/s00104-022-01677-w},
	doi = {10.1007/s00104-022-01677-w},
	abstract = {Intraoperative Bildgebung unterstützt Chirurgen bei minimal-invasiven Eingriffen. Die hyperspektrale Bildgebung („hyperspectral imaging“, HSI) ist ein nichtinvasives und kontaktloses optisches Verfahren mit großem diagnostischem Potenzial in der Medizin. Die Kombination mit Ansätzen der künstlichen Intelligenz (KI) für die Analyse der HSI-Daten wird in diesem Artikel intelligente HSI genannt.},
	language = {de},
	number = {10},
	urldate = {2023-02-07},
	journal = {Die Chirurgie},
	author = {Chalopin, Claire and Nickel, Felix and Pfahl, Annekatrin and Köhler, Hannes and Maktabi, Marianne and Thieme, René and Sucher, Robert and Jansen-Winkeln, Boris and Studier-Fischer, Alexander and Seidlitz, Silvia and Maier-Hein, Lena and Neumuth, Thomas and Melzer, Andreas and Müller-Stich, Beat Peter and Gockel, Ines},
	month = oct,
	year = {2022},
	pages = {940--947},
	file = {Full Text PDF:/Users/farhanoktavian/Zotero/storage/8WBBB3YY/Chalopin et al. - 2022 - Künstliche Intelligenz und hyperspektrale Bildgebu.pdf:application/pdf},
}

@article{shenson_multispectral_2021,
	title = {Multispectral {Imaging} for {Automated} {Tissue} {Identification} of {Normal} {Human} {Surgical} {Specimens}},
	volume = {164},
	issn = {0194-5998},
	url = {https://doi.org/10.1177/0194599820941013},
	doi = {10.1177/0194599820941013},
	abstract = {ObjectiveSafe surgery requires the accurate discrimination of tissue intraoperatively. We assess the feasibility of using multispectral imaging and deep learning to enhance surgical vision by automated identification of normal human head and neck tissues.Study DesignConstruction and feasibility testing of novel multispectral imaging system for surgery.SettingAcademic university hospital.Subjects and MethodsMultispectral images of fresh-preserved human cadaveric tissues were captured with our adapted digital operating microscope. Eleven tissue types were sampled, each sequentially exposed to 6 lighting conditions. Two convolutional neural network machine learning models were developed to classify tissues based on multispectral and white-light color images (ARRInet-M and ARRInet-W, respectively). Blinded otolaryngology residents were asked to identify tissue specimens from white-light color images, and their performance was compared with that of the ARRInet models.ResultsA novel multispectral imaging system was developed with minimal adaptation to an existing digital operating microscope. With 81.8\% accuracy in tissue identification of full-size images, the multispectral ARRInet-M classifier outperformed the white-light-only ARRInet-W model (45.5\%) and surgical residents (69.7\%). Challenges with discrimination occurred with parotid vs fat and blood vessels vs nerve.ConclusionsA deep learning model using multispectral imaging outperformed a similar model and surgical residents using traditional white-light imaging at the task of classifying normal human head and neck tissue ex vivo. These results suggest that multispectral imaging can enhance surgical vision and augment surgeons? ability to identify tissues during a procedure.},
	language = {en},
	number = {2},
	urldate = {2023-02-14},
	journal = {Otolaryngology–Head and Neck Surgery},
	author = {Shenson, Jared A. and Liu, George S. and Farrell, Joyce and Blevins, Nikolas H.},
	month = feb,
	year = {2021},
	note = {Publisher: SAGE Publications Inc},
	pages = {328--335},
	file = {SAGE PDF Full Text:/Users/farhanoktavian/Zotero/storage/B2AWI4D5/Shenson et al. - 2021 - Multispectral Imaging for Automated Tissue Identif.pdf:application/pdf},
}

@inproceedings{leon_hyperspectral_2022,
	title = {Hyperspectral imaging for in-vivo/ex-vivo tissue analysis of human brain cancer},
	volume = {12034},
	url = {https://www.spiedigitallibrary.org/conference-proceedings-of-spie/12034/1203429/Hyperspectral-imaging-for-in-vivo-ex-vivo-tissue-analysis-of/10.1117/12.2611420.full},
	doi = {10.1117/12.2611420},
	abstract = {Accurate identification of tumor boundaries during brain cancer surgery determines the quality of life of the patient. Different intraoperative guidance tools are currently employed during the resection tumor but having several limitations. Hyperspectral imaging (HSI) is arising as a label-free and non-ionizing technique that could assist neurosurgeons during surgical procedures. In this paper, an analysis between in-vivo and ex-vivo human brain tumor samples using HSI has been performed to evaluate the correlation between both types of samples. Spectral ratios of the oxygenated and deoxygenated hemoglobin were employed to distinguish between normal tissue, tumor tissue and blood vessels. A database composed by seven in-vivo and fourteen ex-vivo hyperspectral images obtained from seven different patients diagnosed with glioblastoma Grade IV, metastatic secondary breast cancer, meningioma Grade I and II, and astrocytoma (glioma) Grade II. 44,964 pixels labeled pixels were employed in this work. The proposed method achieved discrimination between different tissue types using the proposed spectral ratio. Comparison between in-vivo and ex-vivo samples indicated that ex-vivo samples generate higher hemoglobin ratios. Moreover, vascular enhanced maps were generated using the spectral ratio, targeting real-time intraoperative surgical assistance.},
	urldate = {2023-02-19},
	booktitle = {Medical {Imaging} 2022: {Image}-{Guided} {Procedures}, {Robotic} {Interventions}, and {Modeling}},
	publisher = {SPIE},
	author = {Leon, Raquel and Gelado, Sofia H. and Fabelo, Himar and Ortega, Samuel and Quintana, Laura and Szolna, Adam and Piñeiro, Juan F. and Balea-Fernandez, Francisco and Morera, Jesus and Clavo, Bernardino and Callico, Gustavo M.},
	month = apr,
	year = {2022},
	pages = {525--534},
	file = {Full Text PDF:/Users/farhanoktavian/Zotero/storage/SDPN67V2/Leon et al. - 2022 - Hyperspectral imaging for in-vivoex-vivo tissue a.pdf:application/pdf},
}

@article{wu_review_2022,
	title = {Review on the {Application} of {Hyperspectral} {Imaging} {Technology} of the {Exposed} {Cortex} in {Cerebral} {Surgery}},
	volume = {10},
	issn = {2296-4185},
	url = {https://www.frontiersin.org/articles/10.3389/fbioe.2022.906728},
	abstract = {The study of brain science is vital to human health. The application of hyperspectral imaging in biomedical fields has grown dramatically in recent years due to their unique optical imaging method and multidimensional information acquisition. Hyperspectral imaging technology can acquire two-dimensional spatial information and one-dimensional spectral information of biological samples simultaneously, covering the ultraviolet, visible and infrared spectral ranges with high spectral resolution, which can provide diagnostic information about the physiological, morphological and biochemical components of tissues and organs. This technology also presents finer spectral features for brain imaging studies, and further provides more auxiliary information for cerebral disease research. This paper reviews the recent advance of hyperspectral imaging in cerebral diagnosis. Firstly, the experimental setup, image acquisition and pre-processing, and analysis methods of hyperspectral technology were introduced. Secondly, the latest research progress and applications of hyperspectral imaging in brain tissue metabolism, hemodynamics, and brain cancer diagnosis in recent years were summarized briefly. Finally, the limitations of the application of hyperspectral imaging in cerebral disease diagnosis field were analyzed, and the future development direction was proposed.},
	urldate = {2023-02-22},
	journal = {Frontiers in Bioengineering and Biotechnology},
	author = {Wu, Yue and Xu, Zhongyuan and Yang, Wenjian and Ning, Zhiqiang and Dong, Hao},
	year = {2022},
	file = {Full Text PDF:/Users/farhanoktavian/Zotero/storage/TLISB6RM/Wu et al. - 2022 - Review on the Application of Hyperspectral Imaging.pdf:application/pdf},
}

@article{manni_hyperspectral_2020,
	title = {Hyperspectral {Imaging} for {Glioblastoma} {Surgery}: {Improving} {Tumor} {Identification} {Using} a {Deep} {Spectral}-{Spatial} {Approach}},
	volume = {20},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {1424-8220},
	shorttitle = {Hyperspectral {Imaging} for {Glioblastoma} {Surgery}},
	url = {https://www.mdpi.com/1424-8220/20/23/6955},
	doi = {10.3390/s20236955},
	abstract = {The primary treatment for malignant brain tumors is surgical resection. While gross total resection improves the prognosis, a supratotal resection may result in neurological deficits. On the other hand, accurate intraoperative identification of the tumor boundaries may be very difficult, resulting in subtotal resections. Histological examination of biopsies can be used repeatedly to help achieve gross total resection but this is not practically feasible due to the turn-around time of the tissue analysis. Therefore, intraoperative techniques to recognize tissue types are investigated to expedite the clinical workflow for tumor resection and improve outcome by aiding in the identification and removal of the malignant lesion. Hyperspectral imaging (HSI) is an optical imaging technique with the power of extracting additional information from the imaged tissue. Because HSI images cannot be visually assessed by human observers, we instead exploit artificial intelligence techniques and leverage a Convolutional Neural Network (CNN) to investigate the potential of HSI in twelve in vivo specimens. The proposed framework consists of a 3D–2D hybrid CNN-based approach to create a joint extraction of spectral and spatial information from hyperspectral images. A comparison study was conducted exploiting a 2D CNN, a 1D DNN and two conventional classification methods (SVM, and the SVM classifier combined with the 3D–2D hybrid CNN) to validate the proposed network. An overall accuracy of 80\% was found when tumor, healthy tissue and blood vessels were classified, clearly outperforming the state-of-the-art approaches. These results can serve as a basis for brain tumor classification using HSI, and may open future avenues for image-guided neurosurgical applications.},
	language = {en},
	number = {23},
	urldate = {2023-02-22},
	journal = {Sensors},
	author = {Manni, Francesca and van der Sommen, Fons and Fabelo, Himar and Zinger, Svitlana and Shan, Caifeng and Edström, Erik and Elmi-Terander, Adrian and Ortega, Samuel and Marrero Callicó, Gustavo and de With, Peter H. N.},
	month = jan,
	year = {2020},
	note = {Number: 23
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {deep learning, ant-colony-based band selection, brain imaging, glioblastoma, hyperspectral imaging, tumor tissue classification},
	pages = {6955},
	file = {Full Text PDF:/Users/farhanoktavian/Zotero/storage/JYBI9FRH/Manni et al. - 2020 - Hyperspectral Imaging for Glioblastoma Surgery Im.pdf:application/pdf},
}

@misc{giannantonio_intra-operative_2023,
	title = {Intra-operative {Brain} {Tumor} {Detection} with {Deep} {Learning}-{Optimized} {Hyperspectral} {Imaging}},
	url = {http://arxiv.org/abs/2302.02884},
	doi = {10.48550/arXiv.2302.02884},
	abstract = {Surgery for gliomas (intrinsic brain tumors), especially when low-grade, is challenging due to the infiltrative nature of the lesion. Currently, no real-time, intra-operative, label-free and wide-field tool is available to assist and guide the surgeon to find the relevant demarcations for these tumors. While marker-based methods exist for the high-grade glioma case, there is no convenient solution available for the low-grade case; thus, marker-free optical techniques represent an attractive option. Although RGB imaging is a standard tool in surgical microscopes, it does not contain sufficient information for tissue differentiation. We leverage the richer information from hyperspectral imaging (HSI), acquired with a snapscan camera in the 468-787 nm range, coupled to a surgical microscope, to build a deep-learning-based diagnostic tool for cancer resection with potential for intra-operative guidance. However, the main limitation of the HSI snapscan camera is the image acquisition time, limiting its widespread deployment in the operation theater. Here, we investigate the effect of HSI channel reduction and pre-selection to scope the design space for the development of cheaper and faster sensors. Neural networks are used to identify the most important spectral channels for tumor tissue differentiation, optimizing the trade-off between the number of channels and precision to enable real-time intra-surgical application. We evaluate the performance of our method on a clinical dataset that was acquired during surgery on five patients. By demonstrating the possibility to efficiently detect low-grade glioma, these results can lead to better cancer resection demarcations, potentially improving treatment effectiveness and patient outcome.},
	urldate = {2023-02-22},
	publisher = {arXiv},
	author = {Giannantonio, Tommaso and Alperovich, Anna and Semeraro, Piercosimo and Atzori, Manfredo and Zhang, Xiaohan and Hauger, Christoph and Freytag, Alexander and Luthman, Siri and Vandebriel, Roeland and Jayapala, Murali and Solie, Lien and de Vleeschouwer, Steven},
	month = feb,
	year = {2023},
	note = {arXiv:2302.02884 [cs, eess]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Electrical Engineering and Systems Science - Image and Video Processing},
	file = {arXiv Fulltext PDF:/Users/farhanoktavian/Zotero/storage/PENRPBR7/Giannantonio et al. - 2023 - Intra-operative Brain Tumor Detection with Deep Le.pdf:application/pdf;arXiv.org Snapshot:/Users/farhanoktavian/Zotero/storage/NXJ2UXLK/2302.html:text/html},
}

@misc{yun_spectr_2021,
	title = {{SpecTr}: {Spectral} {Transformer} for {Hyperspectral} {Pathology} {Image} {Segmentation}},
	shorttitle = {{SpecTr}},
	url = {http://arxiv.org/abs/2103.03604},
	doi = {10.48550/arXiv.2103.03604},
	abstract = {Hyperspectral imaging (HSI) unlocks the huge potential to a wide variety of applications relied on high-precision pathology image segmentation, such as computational pathology and precision medicine. Since hyperspectral pathology images benefit from the rich and detailed spectral information even beyond the visible spectrum, the key to achieve high-precision hyperspectral pathology image segmentation is to felicitously model the context along high-dimensional spectral bands. Inspired by the strong context modeling ability of transformers, we hereby, for the first time, formulate the contextual feature learning across spectral bands for hyperspectral pathology image segmentation as a sequence-to-sequence prediction procedure by transformers. To assist spectral context learning procedure, we introduce two important strategies: (1) a sparsity scheme enforces the learned contextual relationship to be sparse, so as to eliminates the distraction from the redundant bands; (2) a spectral normalization, a separate group normalization for each spectral band, mitigates the nuisance caused by heterogeneous underlying distributions of bands. We name our method Spectral Transformer (SpecTr), which enjoys two benefits: (1) it has a strong ability to model long-range dependency among spectral bands, and (2) it jointly explores the spatial-spectral features of HSI. Experiments show that SpecTr outperforms other competing methods in a hyperspectral pathology image segmentation benchmark without the need of pre-training. Code is available at https://github.com/hfut-xc-yun/SpecTr.},
	urldate = {2023-02-27},
	publisher = {arXiv},
	author = {Yun, Boxiang and Wang, Yan and Chen, Jieneng and Wang, Huiyu and Shen, Wei and Li, Qingli},
	month = mar,
	year = {2021},
	note = {arXiv:2103.03604 [cs, eess]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Electrical Engineering and Systems Science - Image and Video Processing},
	file = {arXiv Fulltext PDF:/Users/farhanoktavian/Zotero/storage/SNP4JASG/Yun et al. - 2021 - SpecTr Spectral Transformer for Hyperspectral Pat.pdf:application/pdf;arXiv.org Snapshot:/Users/farhanoktavian/Zotero/storage/NRQYJQNH/2103.html:text/html},
}

@article{hao_fusing_2021,
	title = {Fusing {Multiple} {Deep} {Models} for {In} {Vivo} {Human} {Brain} {Hyperspectral} {Image} {Classification} to {Identify} {Glioblastoma} {Tumor}},
	volume = {70},
	issn = {1557-9662},
	doi = {10.1109/TIM.2021.3117634},
	abstract = {Glioblastoma (GBM) tumor is the most common primary brain malignant tumor. The precise identification of GBM tumors is very important for diagnosis and treatment. Hyperspectral imaging is a fast, noncontact, accurate, and safe modern medical detection technology, which is expected to be a new tool of intraoperative diagnosis. In order to make full use of the spectral and spatial information of hyperspectral images (HSIs) to achieve accurate GBM tumor identification, a method based on the fusion of multiple deep models is proposed for in vivo human brain HSI classification. The proposed method includes the following major steps: 1) spectral phasor analysis and data oversampling; 2) 1-D deep neural network (1D-DNN)-based spectral HSI feature extraction and classification; 3) 2-D convolution neural network (2D-CNN)-based spectral–spatial HSI feature extraction and classification; 4) edge-preserving filtering-based classification result fusion and optimization; and 5) fully convolutional network (FCN)-based background segmentation. To verify the capabilities of the proposed method, experiments are performed on two real human brain hyperspectral datasets, including 36 in vivo HSIs captured from 16 different patients. The proposed method can achieve an overall accuracy of 96.69\% for four-class classification and overall accuracy of 96.34\% for GBM tumor identification. Experimental results demonstrate that the proposed method exhibits competitive classification performance and can generate satisfactory thematic maps of the location of the GBM tumor, which can provide the surgeon with guidance on successful and precise tumor resection.},
	journal = {IEEE Transactions on Instrumentation and Measurement},
	author = {Hao, Qiaobo and Pei, Yu and Zhou, Rong and Sun, Bin and Sun, Jun and Li, Shutao and Kang, Xudong},
	year = {2021},
	note = {Conference Name: IEEE Transactions on Instrumentation and Measurement},
	keywords = {Deep learning, Hyperspectral imaging, Image segmentation, Brain modeling, Computational modeling, Feature extraction, hyperspectral image (HSI) classification, identification of glioblastoma (GBM) tumor, intraoperative imaging, precision medicine, Tumors},
	pages = {1--14},
	file = {IEEE Xplore Abstract Record:/Users/farhanoktavian/Zotero/storage/2S6SZK2U/9562441.html:text/html;IEEE Xplore Full Text PDF:/Users/farhanoktavian/Zotero/storage/C7Q8UTWR/Hao et al. - 2021 - Fusing Multiple Deep Models for In Vivo Human Brai.pdf:application/pdf},
}

@article{ravi_manifold_2017,
	title = {Manifold {Embedding} and {Semantic} {Segmentation} for {Intraoperative} {Guidance} {With} {Hyperspectral} {Brain} {Imaging}},
	volume = {36},
	issn = {1558-254X},
	doi = {10.1109/TMI.2017.2695523},
	abstract = {Recent advances in hyperspectral imaging have made it a promising solution for intra-operative tissue characterization, with the advantages of being non-contact, non-ionizing, and non-invasive. Working with hyperspectral images in vivo, however, is not straightforward as the high dimensionality of the data makes real-time processing challenging. In this paper, a novel dimensionality reduction scheme and a new processing pipeline are introduced to obtain a detailed tumor classification map for intra-operative margin definition during brain surgery. However, existing approaches to dimensionality reduction based on manifold embedding can be time consuming and may not guarantee a consistent result, thus hindering final tissue classification. The proposed framework aims to overcome these problems through a process divided into two steps: dimensionality reduction based on an extension of the T-distributed stochastic neighbor approach is first performed and then a semantic segmentation technique is applied to the embedded results by using a Semantic Texton Forest for tissue classification. Detailed in vivo validation of the proposed method has been performed to demonstrate the potential clinical value of the system.},
	number = {9},
	journal = {IEEE Transactions on Medical Imaging},
	author = {Ravì, Daniele and Fabelo, Himar and Callic, Gustavo Marrero and Yang, Guang-Zhong},
	month = sep,
	year = {2017},
	note = {Conference Name: IEEE Transactions on Medical Imaging},
	keywords = {Hyperspectral imaging, Image segmentation, hyperspectral imaging, Tumors, Brain, brain cancer detection, Cancer, Manifold embedding, Manifolds, semantic segmentation, Semantics},
	pages = {1845--1857},
	file = {IEEE Xplore Abstract Record:/Users/farhanoktavian/Zotero/storage/9EMYQJ8C/7907323.html:text/html;IEEE Xplore Full Text PDF:/Users/farhanoktavian/Zotero/storage/PLZKU7WA/Ravì et al. - 2017 - Manifold Embedding and Semantic Segmentation for I.pdf:application/pdf},
}

@article{ortega_hyperspectral_2020,
	title = {Hyperspectral {Imaging} for the {Detection} of {Glioblastoma} {Tumor} {Cells} in {H}\&{E} {Slides} {Using} {Convolutional} {Neural} {Networks}},
	volume = {20},
	issn = {1424-8220},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7181269/},
	doi = {10.3390/s20071911},
	abstract = {Hyperspectral imaging (HSI) technology has demonstrated potential to provide useful information about the chemical composition of tissue and its morphological features in a single image modality. Deep learning (DL) techniques have demonstrated the ability of automatic feature extraction from data for a successful classification. In this study, we exploit HSI and DL for the automatic differentiation of glioblastoma (GB) and non-tumor tissue on hematoxylin and eosin (H\&E) stained histological slides of human brain tissue. GB detection is a challenging application, showing high heterogeneity in the cellular morphology across different patients. We employed an HSI microscope, with a spectral range from 400 to 1000 nm, to collect 517 HS cubes from 13 GB patients using 20× magnification. Using a convolutional neural network (CNN), we were able to automatically detect GB within the pathological slides, achieving average sensitivity and specificity values of 88\% and 77\%, respectively, representing an improvement of 7\% and 8\% respectively, as compared to the results obtained using RGB (red, green, and blue) images. This study demonstrates that the combination of hyperspectral microscopic imaging and deep learning is a promising tool for future computational pathologies.},
	number = {7},
	urldate = {2023-02-28},
	journal = {Sensors (Basel, Switzerland)},
	author = {Ortega, Samuel and Halicek, Martin and Fabelo, Himar and Camacho, Rafael and Plaza, María de la Luz and Godtliebsen, Fred and M. Callicó, Gustavo and Fei, Baowei},
	month = mar,
	year = {2020},
	pmid = {32235483},
	pmcid = {PMC7181269},
	pages = {1911},
	file = {PubMed Central Full Text PDF:/Users/farhanoktavian/Zotero/storage/Y8Q9Y7I2/Ortega et al. - 2020 - Hyperspectral Imaging for the Detection of Gliobla.pdf:application/pdf},
}

@article{torti_parallel_2018,
	title = {Parallel {K}-{Means} {Clustering} for {Brain} {Cancer} {Detection} {Using} {Hyperspectral} {Images}},
	volume = {7},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2079-9292},
	url = {https://www.mdpi.com/2079-9292/7/11/283},
	doi = {10.3390/electronics7110283},
	abstract = {The precise delineation of brain cancer is a crucial task during surgery. There are several techniques employed during surgical procedures to guide neurosurgeons in the tumor resection. However, hyperspectral imaging (HSI) is a promising non-invasive and non-ionizing imaging technique that could improve and complement the currently used methods. The HypErspectraL Imaging Cancer Detection (HELICoiD) European project has addressed the development of a methodology for tumor tissue detection and delineation exploiting HSI techniques. In this approach, the K-means algorithm emerged in the delimitation of tumor borders, which is of crucial importance. The main drawback is the computational complexity of this algorithm. This paper describes the development of the K-means clustering algorithm on different parallel architectures, in order to provide real-time processing during surgical procedures. This algorithm will generate an unsupervised segmentation map that, combined with a supervised classification map, will offer guidance to the neurosurgeon during the tumor resection task. We present parallel K-means clustering based on OpenMP, CUDA and OpenCL paradigms. These algorithms have been validated through an in-vivo hyperspectral human brain image database. Experimental results show that the CUDA version can achieve a speed-up of {\textasciitilde}    150 ×     with respect to a sequential processing. The remarkable result obtained in this paper makes possible the development of a real-time classification system.},
	language = {en},
	number = {11},
	urldate = {2023-02-28},
	journal = {Electronics},
	author = {Torti, Emanuele and Florimbi, Giordana and Castelli, Francesca and Ortega, Samuel and Fabelo, Himar and Callicó, Gustavo Marrero and Marrero-Martin, Margarita and Leporati, Francesco},
	month = nov,
	year = {2018},
	note = {Number: 11
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {hyperspectral imaging, brain cancer detection, CUDA, Graphics Processing Units (GPUs), K-means, OpenCL, OpenMP, unsupervised clustering},
	pages = {283},
	file = {Full Text PDF:/Users/farhanoktavian/Zotero/storage/B7VG6DPP/Torti et al. - 2018 - Parallel K-Means Clustering for Brain Cancer Detec.pdf:application/pdf},
}

@article{martinez_most_2019,
	title = {Most {Relevant} {Spectral} {Bands} {Identification} for {Brain} {Cancer} {Detection} {Using} {Hyperspectral} {Imaging}},
	volume = {19},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {1424-8220},
	url = {https://www.mdpi.com/1424-8220/19/24/5481},
	doi = {10.3390/s19245481},
	abstract = {Hyperspectral imaging (HSI) is a non-ionizing and non-contact imaging technique capable of obtaining more information than conventional RGB (red green blue) imaging. In the medical field, HSI has commonly been investigated due to its great potential for diagnostic and surgical guidance purposes. However, the large amount of information provided by HSI normally contains redundant or non-relevant information, and it is extremely important to identify the most relevant wavelengths for a certain application in order to improve the accuracy of the predictions and reduce the execution time of the classification algorithm. Additionally, some wavelengths can contain noise and removing such bands can improve the classification stage. The work presented in this paper aims to identify such relevant spectral ranges in the visual-and-near-infrared (VNIR) region for an accurate detection of brain cancer using in vivo hyperspectral images. A methodology based on optimization algorithms has been proposed for this task, identifying the relevant wavelengths to achieve the best accuracy in the classification results obtained by a supervised classifier (support vector machines), and employing the lowest possible number of spectral bands. The results demonstrate that the proposed methodology based on the genetic algorithm optimization slightly improves the accuracy of the tumor identification in {\textasciitilde}5\%, using only 48 bands, with respect to the reference results obtained with 128 bands, offering the possibility of developing customized acquisition sensors that could provide real-time HS imaging. The most relevant spectral ranges found comprise between 440.5–465.96 nm, 498.71–509.62 nm, 556.91–575.1 nm, 593.29–615.12 nm, 636.94–666.05 nm, 698.79–731.53 nm and 884.32–902.51 nm.},
	language = {en},
	number = {24},
	urldate = {2023-02-28},
	journal = {Sensors},
	author = {Martinez, Beatriz and Leon, Raquel and Fabelo, Himar and Ortega, Samuel and Piñeiro, Juan F. and Szolna, Adam and Hernandez, Maria and Espino, Carlos and J. O’Shanahan, Aruma and Carrera, David and Bisshopp, Sara and Sosa, Coralia and Marquez, Mariano and Camacho, Rafael and Plaza, Maria de la Luz and Morera, Jesus and M. Callico, Gustavo},
	month = jan,
	year = {2019},
	note = {Number: 24
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {machine learning, hyperspectral imaging, intraoperative imaging, ant colony optimization, brain cancer, feature selection, genetic algorithm, image-guided surgery, particle swarm optimization, support vector machine},
	pages = {5481},
	file = {Full Text PDF:/Users/farhanoktavian/Zotero/storage/E9FJAKVA/Martinez et al. - 2019 - Most Relevant Spectral Bands Identification for Br.pdf:application/pdf},
}

@article{fabelo_-vivo_2019,
	title = {In-{Vivo} {Hyperspectral} {Human} {Brain} {Image} {Database} for {Brain} {Cancer} {Detection}},
	volume = {7},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2019.2904788},
	abstract = {The use of hyperspectral imaging for medical applications is becoming more common in recent years. One of the main obstacles that researchers find when developing hyperspectral algorithms for medical applications is the lack of specific, publicly available, and hyperspectral medical data. The work described in this paper was developed within the framework of the European project HELICoiD (HypErspectraL Imaging Cancer Detection), which had as a main goal the application of hyperspectral imaging to the delineation of brain tumors in real-time during neurosurgical operations. In this paper, the methodology followed to generate the first hyperspectral database of in-vivo human brain tissues is presented. Data was acquired employing a customized hyperspectral acquisition system capable of capturing information in the Visual and Near InfraRed (VNIR) range from 400 to 1000 nm. Repeatability was assessed for the cases where two images of the same scene were captured consecutively. The analysis reveals that the system works more efficiently in the spectral range between 450 and 900 nm. A total of 36 hyperspectral images from 22 different patients were obtained. From these data, more than 300 000 spectral signatures were labeled employing a semi-automatic methodology based on the spectral angle mapper algorithm. Four different classes were defined: normal tissue, tumor tissue, blood vessel, and background elements. All the hyperspectral data has been made available in a public repository.},
	journal = {IEEE Access},
	author = {Fabelo, Himar and Ortega, Samuel and Szolna, Adam and Bulters, Diederik and Piñeiro, Juan F. and Kabwama, Silvester and J-O'Shanahan, Aruma and Bulstrode, Harry and Bisshopp, Sara and Kiran, B. Ravi and Ravi, Daniele and Lazcano, Raquel and Madroñal, Daniel and Sosa, Coralia and Espino, Carlos and Marquez, Mariano and De La Luz Plaza, María and Camacho, Rafael and Carrera, David and Hernández, María and Callicó, Gustavo M. and Morera Molina, Jesús and Stanciulescu, Bogdan and Yang, Guang-Zhong and Salvador, Rubén and Juárez, Eduardo and Sanz, César and Sarmiento, Roberto},
	year = {2019},
	note = {Conference Name: IEEE Access},
	keywords = {Surgery, Hyperspectral imaging, Tumors, Brain, biomedical imaging, cancer detection, Hospitals, image databases, Magnetic resonance imaging, medical diagnostic imaging},
	pages = {39098--39116},
	file = {IEEE Xplore Abstract Record:/Users/farhanoktavian/Zotero/storage/ZMXT88VH/8667294.html:text/html;IEEE Xplore Full Text PDF:/Users/farhanoktavian/Zotero/storage/JGQRQ992/Fabelo et al. - 2019 - In-Vivo Hyperspectral Human Brain Image Database f.pdf:application/pdf},
}

@article{halicek_-vivo_2019,
	title = {In-{Vivo} and {Ex}-{Vivo} {Tissue} {Analysis} through {Hyperspectral} {Imaging} {Techniques}: {Revealing} the {Invisible} {Features} of {Cancer}},
	volume = {11},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2072-6694},
	shorttitle = {In-{Vivo} and {Ex}-{Vivo} {Tissue} {Analysis} through {Hyperspectral} {Imaging} {Techniques}},
	url = {https://www.mdpi.com/2072-6694/11/6/756},
	doi = {10.3390/cancers11060756},
	abstract = {In contrast to conventional optical imaging modalities, hyperspectral imaging (HSI) is able to capture much more information from a certain scene, both within and beyond the visual spectral range (from 400 to 700 nm). This imaging modality is based on the principle that each material provides different responses to light reflection, absorption, and scattering across the electromagnetic spectrum. Due to these properties, it is possible to differentiate and identify the different materials/substances presented in a certain scene by their spectral signature. Over the last two decades, HSI has demonstrated potential to become a powerful tool to study and identify several diseases in the medical field, being a non-contact, non-ionizing, and a label-free imaging modality. In this review, the use of HSI as an imaging tool for the analysis and detection of cancer is presented. The basic concepts related to this technology are detailed. The most relevant, state-of-the-art studies that can be found in the literature using HSI for cancer analysis are presented and summarized, both in-vivo and ex-vivo. Lastly, we discuss the current limitations of this technology in the field of cancer detection, together with some insights into possible future steps in the improvement of this technology.},
	language = {en},
	number = {6},
	urldate = {2023-02-28},
	journal = {Cancers},
	author = {Halicek, Martin and Fabelo, Himar and Ortega, Samuel and Callico, Gustavo M. and Fei, Baowei},
	month = jun,
	year = {2019},
	note = {Number: 6
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {artificial intelligence, machine learning, hyperspectral imaging, medical diagnostic imaging, biomedical optical imaging, cancer, clinical diagnosis},
	pages = {756},
	file = {Full Text PDF:/Users/farhanoktavian/Zotero/storage/4S395UTT/Halicek et al. - 2019 - In-Vivo and Ex-Vivo Tissue Analysis through Hypers.pdf:application/pdf},
}

@article{fabelo_intraoperative_2018,
	title = {An {Intraoperative} {Visualization} {System} {Using} {Hyperspectral} {Imaging} to {Aid} in {Brain} {Tumor} {Delineation}},
	volume = {18},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {1424-8220},
	url = {https://www.mdpi.com/1424-8220/18/2/430},
	doi = {10.3390/s18020430},
	abstract = {Hyperspectral imaging (HSI) allows for the acquisition of large numbers of spectral bands throughout the electromagnetic spectrum (within and beyond the visual range) with respect to the surface of scenes captured by sensors. Using this information and a set of complex classification algorithms, it is possible to determine which material or substance is located in each pixel. The work presented in this paper aims to exploit the characteristics of HSI to develop a demonstrator capable of delineating tumor tissue from brain tissue during neurosurgical operations. Improved delineation of tumor boundaries is expected to improve the results of surgery. The developed demonstrator is composed of two hyperspectral cameras covering a spectral range of 400–1700 nm. Furthermore, a hardware accelerator connected to a control unit is used to speed up the hyperspectral brain cancer detection algorithm to achieve processing during the time of surgery. A labeled dataset comprised of more than 300,000 spectral signatures is used as the training dataset for the supervised stage of the classification algorithm. In this preliminary study, thematic maps obtained from a validation database of seven hyperspectral images of in vivo brain tissue captured and processed during neurosurgical operations demonstrate that the system is able to discriminate between normal and tumor tissue in the brain. The results can be provided during the surgical procedure ({\textasciitilde}1 min), making it a practical system for neurosurgeons to use in the near future to improve excision and potentially improve patient outcomes.},
	language = {en},
	number = {2},
	urldate = {2023-02-28},
	journal = {Sensors},
	author = {Fabelo, Himar and Ortega, Samuel and Lazcano, Raquel and Madroñal, Daniel and M. Callicó, Gustavo and Juárez, Eduardo and Salvador, Rubén and Bulters, Diederik and Bulstrode, Harry and Szolna, Adam and Piñeiro, Juan F. and Sosa, Coralia and J. O’Shanahan, Aruma and Bisshopp, Sara and Hernández, María and Morera, Jesús and Ravi, Daniele and Kiran, B. Ravi and Vega, Aurelio and Báez-Quevedo, Abelardo and Yang, Guang-Zhong and Stanciulescu, Bogdan and Sarmiento, Roberto},
	month = feb,
	year = {2018},
	note = {Number: 2
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {brain cancer detection, hyperspectral imaging instrumentation, image processing},
	pages = {430},
	file = {Full Text PDF:/Users/farhanoktavian/Zotero/storage/5ZZ3NSIA/Fabelo et al. - 2018 - An Intraoperative Visualization System Using Hyper.pdf:application/pdf},
}

@article{khan_trends_2021,
	title = {Trends in {Deep} {Learning} for {Medical} {Hyperspectral} {Image} {Analysis}},
	volume = {9},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2021.3068392},
	abstract = {Deep learning algorithms have seen acute growth of interest in their applications throughout several fields of interest in the last decade, with medical hyperspectral imaging being a particularly promising domain. So far, to the best of our knowledge, there is no review paper that discusses the implementation of deep learning for medical hyperspectral imaging, which is what this work aims to accomplish by examining publications that currently utilize deep learning to perform effective analysis of medical hyperspectral imagery. This paper discusses deep learning concepts that are relevant and applicable to medical hyperspectral imaging analysis, several of which have been implemented since the boom in deep learning. This will comprise of reviewing the use of deep learning for classification, segmentation, and detection in order to investigate the analysis of medical hyperspectral imaging. Lastly, we discuss the current and future challenges pertaining to this discipline and the possible efforts to overcome such trials.},
	journal = {IEEE Access},
	author = {Khan, Uzair and Paheding, Sidike and Elkin, Colin P. and Devabhaktuni, Vijaya Kumar},
	year = {2021},
	note = {Conference Name: IEEE Access},
	keywords = {Deep learning, Hyperspectral imaging, machine learning, Cancer, Classification algorithms, Imaging, Medical diagnostic imaging, medical hyperspectral imaging, medical image analysis, neural networks, X-rays},
	pages = {79534--79548},
	file = {IEEE Xplore Abstract Record:/Users/farhanoktavian/Zotero/storage/ED5UXC8T/9385082.html:text/html;IEEE Xplore Full Text PDF:/Users/farhanoktavian/Zotero/storage/DYUYSAVX/Khan et al. - 2021 - Trends in Deep Learning for Medical Hyperspectral .pdf:application/pdf},
}

@article{aydin_usage_2021,
	title = {On the usage of average {Hausdorff} distance for segmentation performance assessment: hidden error when used for ranking},
	volume = {5},
	issn = {2509-9280},
	shorttitle = {On the usage of average {Hausdorff} distance for segmentation performance assessment},
	url = {https://doi.org/10.1186/s41747-020-00200-2},
	doi = {10.1186/s41747-020-00200-2},
	abstract = {Average Hausdorff distance is a widely used performance measure to calculate the distance between two point sets. In medical image segmentation, it is used to compare ground truth images with segmentations allowing their ranking. We identified, however, ranking errors of average Hausdorff distance making it less suitable for applications in segmentation performance assessment. To mitigate this error, we present a modified calculation of this performance measure that we have coined “balanced average Hausdorff distance”. To simulate segmentations for ranking, we manually created non-overlapping segmentation errors common in magnetic resonance angiography cerebral vessel segmentation as our use-case. Adding the created errors consecutively and randomly to the ground truth, we created sets of simulated segmentations with increasing number of errors. Each set of simulated segmentations was ranked using both performance measures. We calculated the Kendall rank correlation coefficient between the segmentation ranking and the number of errors in each simulated segmentation. The rankings produced by balanced average Hausdorff distance had a significantly higher median correlation (1.00) than those by average Hausdorff distance (0.89). In 200 total rankings, the former misranked 52 whilst the latter misranked 179 segmentations. Balanced average Hausdorff distance is more suitable for rankings and quality assessment of segmentations than average Hausdorff distance.},
	number = {1},
	urldate = {2023-03-01},
	journal = {European Radiology Experimental},
	author = {Aydin, Orhun Utku and Taha, Abdel Aziz and Hilbert, Adam and Khalil, Ahmed A. and Galinovic, Ivana and Fiebach, Jochen B. and Frey, Dietmar and Madai, Vince Istvan},
	month = jan,
	year = {2021},
	keywords = {Average Hausdorff distance, Cerebral angiography, Cerebral arteries, Image processing (computer-assisted)},
	pages = {4},
	file = {Full Text PDF:/Users/farhanoktavian/Zotero/storage/3YIM37JT/Aydin et al. - 2021 - On the usage of average Hausdorff distance for seg.pdf:application/pdf;Snapshot:/Users/farhanoktavian/Zotero/storage/YZ39L84N/s41747-020-00200-2.html:text/html},
}

@article{murphy_finley_1996,
	title = {The {Finley} {Affair}: {A} {Signal} {Event} in the {History} of {Forecast} {Verification}},
	volume = {11},
	issn = {1520-0434, 0882-8156},
	shorttitle = {The {Finley} {Affair}},
	url = {https://journals.ametsoc.org/view/journals/wefo/11/1/1520-0434_1996_011_0003_tfaase_2_0_co_2.xml},
	doi = {10.1175/1520-0434(1996)011<0003:TFAASE>2.0.CO;2},
	abstract = {Abstract In 1884 a paper by J.P. Finley appeared in the American Meteorological Journal describing the results of an experimental tornado forecasting program in the central and eastern United States. Finley's paper reported “percentages of verifications” exceeding 95\%, where this index of performance was defined as the percentage of correct tornado/no-tornado forecasts. Within six months, three papers had appeared that identified deficiencies in Finley's method of verification and/or proposed alternative measures of forecasting performance in the context of this 2×2 verification problem. During the period from 1885 to 1893, several other authors in the United States and Europe, in most cases stimulated either by Finley's paper or by the three early responses, made noteworthy contributions to methods-oriented and practices-oriented discussions of issues related to forecast verification in general and verification of tornado forecasts in particular. The burst of verification-related activities during the period 1884–1893 is referred to here as the “Finley affair.” It marked the beginning of substantive conceptual and methodological developments and discussions in the important subdiscipline of forecast verification. This paper describes the events that constitute the Finley affair in some detail and attempts to place this affair in proper historical context from the perspective of the mid-1990s. Whatever their individual strengths and weaknesses, the measures introduced during the period from 1884 to 1893 have withstood important tests of time—for example, these measures have been rediscovered on one or more occasions and they are still widely used today (generally under names assigned since 1900). Moreover, many of the issues vis-à-vis forecast verification that were first raised during the Finley affair remain issues of considerable importance more than 100 years later.},
	language = {EN},
	number = {1},
	urldate = {2023-03-01},
	journal = {Weather and Forecasting},
	author = {Murphy, Allan H.},
	month = mar,
	year = {1996},
	note = {Publisher: American Meteorological Society
Section: Weather and Forecasting},
	pages = {3--20},
	file = {Full Text PDF:/Users/farhanoktavian/Zotero/storage/DYCPA9KZ/Murphy - 1996 - The Finley Affair A Signal Event in the History o.pdf:application/pdf},
}

@article{dice_measures_1945,
	title = {Measures of the {Amount} of {Ecologic} {Association} {Between} {Species}},
	volume = {26},
	issn = {0012-9658},
	url = {https://www.jstor.org/stable/1932409},
	doi = {10.2307/1932409},
	number = {3},
	urldate = {2023-03-01},
	journal = {Ecology},
	author = {Dice, Lee R.},
	year = {1945},
	note = {Publisher: Ecological Society of America},
	pages = {297--302},
	file = {JSTOR Full Text PDF:/Users/farhanoktavian/Zotero/storage/PXL5AF5T/Dice - 1945 - Measures of the Amount of Ecologic Association Bet.pdf:application/pdf},
}

@article{collins_brain_2004,
	title = {Brain tumours: classification and genes},
	volume = {75},
	copyright = {Copyright 2004 Journal of Neurology Neurosurgery and Psychiatry},
	issn = {0022-3050, 1468-330X},
	shorttitle = {Brain tumours},
	url = {https://jnnp.bmj.com/content/75/suppl_2/ii2},
	doi = {10.1136/jnnp.2004.040337},
	abstract = {This paper aims to provide an outline of the surgical pathology of the most common tumours of the nervous system in children and adults, and briefly summarise their common genetic changes. The reader is referred to more comprehensive texts for further details about brain tumour classification and the genetic abnormalities of these tumours.1

Most recent classifications of brain tumours build on the 1926 work of Bailey and Cushing.2 This classification named tumours after the cell type in the developing embryo/fetus or adult which the tumour cells most resembled histologically. The cell of origin of the majority of brain tumours is unknown as no pre-malignant states are recognised, as is the case in some epithelial tumour forms. In some tumours, cells may be so atypical that it is difficult to compare them with any normal cell type—hence the use of terms such as glioblastoma. Many unsound or illogical terms have remained in the classifications, as once established in a complex medical setting they are difficult to change. In this paper the terminology and definitions of the World Health Organization classification of 2000 will be exclusively used.1 There are more than 120 entities in this classification and here we will concentrate on those that most frequently occur in adults and children. These are the pilocytic astrocytomas, ependymomas, and medulloblastomas in children, and the diffuse astrocytic tumours (including astrocytoma, anaplastic astrocytomas, and glioblastomas), oligodendrogliomas, and meningiomas in adults.

Tumours of the central nervous system often have a wide morphological spectrum and classification is dependent on the recognition of areas with the characteristic histology for a particular tumour type. Immunocytochemical methods may be required to demonstrate the expression by the tumour cells of an antigen typically expressed by a particular cell type and thus to assist in classification. Unfortunately there are …},
	language = {en},
	number = {suppl 2},
	urldate = {2023-03-01},
	journal = {Journal of Neurology, Neurosurgery \& Psychiatry},
	author = {Collins, V. P.},
	month = jun,
	year = {2004},
	pmid = {15146033},
	note = {Publisher: BMJ Publishing Group Ltd},
	keywords = {brain neoplasms, histopathology, immunocytochemistry, morphology, oncogenes, tumour suppressor genes},
	pages = {ii2--ii11},
	file = {Full Text PDF:/Users/farhanoktavian/Zotero/storage/54N9LDBY/Collins - 2004 - Brain tumours classification and genes.pdf:application/pdf},
}

@article{bush_current_2017,
	title = {Current and future strategies for treatment of glioma},
	volume = {40},
	issn = {1437-2320},
	url = {https://doi.org/10.1007/s10143-016-0709-8},
	doi = {10.1007/s10143-016-0709-8},
	abstract = {Gliomas are one of the most common types of primary brain tumors and have remained particularly challenging to treat. This review illustrates a multidisciplinary approach to the treatment of glioma and glioblastoma. We will review current advances in surgical approaches, novel imaging techniques, advanced molecular characterization of tumors and translational efforts for treatment. We will focus on current clinical trials as well as the pursuit of personalized or precision therapy. We will also comment on the importance of both quality of life of our patients and their care givers.},
	language = {en},
	number = {1},
	urldate = {2023-03-01},
	journal = {Neurosurgical Review},
	author = {Bush, Nancy Ann Oberheim and Chang, Susan M. and Berger, Mitchel S.},
	month = jan,
	year = {2017},
	pages = {1--14},
	file = {Full Text PDF:/Users/farhanoktavian/Zotero/storage/S7KYMGDN/Bush et al. - 2017 - Current and future strategies for treatment of gli.pdf:application/pdf},
}

@article{pelagotti_multispectral_2008,
	title = {Multispectral imaging of paintings},
	volume = {25},
	issn = {1558-0792},
	doi = {10.1109/MSP.2008.923095},
	abstract = {Identifying the materials of a painting is a crucial step in any conservation process. When the objective is to prepare an intervention plan, it is absolutely necessary to understand the matters the restorer is going to encounter. Also, when the aim is a better understanding of the artwork, and perhaps an authenticity check, it is highly relevant to know which materials were employed, since they may differ depending on the period of execution and on the specific artist as well. To identify materials on a painting's surface in a reliable manner, currently the most popular and trustworthy method is the analysis of microsamples of the paint layer. However, chemical analyses although reliable, have a number of drawbacks. The first is linked to the fact that this is an invasive method. The samples used need to be detached from the painting and will not be put back in place. Moreover, the achieved results are in principle - and often also in practice - valid only for that specific specimen and cannot generally be extended to neighboring areas.},
	number = {4},
	journal = {IEEE Signal Processing Magazine},
	author = {Pelagotti, Anna and Mastio, Andrea Del and Rosa, Alessia De and Piva, Alessandro},
	month = jul,
	year = {2008},
	note = {Conference Name: IEEE Signal Processing Magazine},
	keywords = {Art, Filters, Image analysis, Materials reliability, Multispectral imaging, Painting, Paints, Raman scattering, Reflectivity, Spectroscopy},
	pages = {27--36},
	file = {IEEE Xplore Abstract Record:/Users/farhanoktavian/Zotero/storage/XN8E7GBH/4545846.html:text/html;IEEE Xplore Full Text PDF:/Users/farhanoktavian/Zotero/storage/F65YYLUG/Pelagotti et al. - 2008 - Multispectral imaging of paintings.pdf:application/pdf},
}

@article{legnaioli_recovery_2013,
	title = {Recovery of archaeological wall paintings using novel multispectral imaging approaches},
	volume = {1},
	issn = {2050-7445},
	url = {https://doi.org/10.1186/2050-7445-1-33},
	doi = {10.1186/2050-7445-1-33},
	abstract = {New approaches in the application of multispectral imaging to the recovery of archeological wall paintings are presented, based on statistical techniques and on a novel method of image treatment (Chromatic Derivative Imaging – ChromaDI) which offers a way of embedding information coming from four spectral bands into a standard RGB image. The methods are applied to some wall paintings from the Tomb of the Monkey, an Etruscan tomb in the necropolis of Poggio Renzo, near the city of Chiusi (Siena), Italy, dated around 480-470 BC. It is shown that the techniques described are able to highlight and enhance a number of details that cannot be perceived in either any of the original channel images or any single processed output channel.},
	language = {en},
	number = {1},
	urldate = {2023-03-03},
	journal = {Heritage Science},
	author = {Legnaioli, Stefano and Lorenzetti, Giulia and Cavalcanti, Gildo H. and Grifoni, Emanuela and Marras, Luciano and Tonazzini, Anna and Salerno, Emanuele and Pallecchi, Pasquino and Giachi, Gianna and Palleschi, Vincenzo},
	month = oct,
	year = {2013},
	pages = {33},
	file = {Full Text PDF:/Users/farhanoktavian/Zotero/storage/E7XQNFH3/Legnaioli et al. - 2013 - Recovery of archaeological wall paintings using no.pdf:application/pdf},
}

@article{berni_thermal_2009,
	title = {Thermal and {Narrowband} {Multispectral} {Remote} {Sensing} for {Vegetation} {Monitoring} {From} an {Unmanned} {Aerial} {Vehicle}},
	volume = {47},
	issn = {1558-0644},
	doi = {10.1109/TGRS.2008.2010457},
	abstract = {Two critical limitations for using current satellite sensors in real-time crop management are the lack of imagery with optimum spatial and spectral resolutions and an unfavorable revisit time for most crop stress-detection applications. Alternatives based on manned airborne platforms are lacking due to their high operational costs. A fundamental requirement for providing useful remote sensing products in agriculture is the capacity to combine high spatial resolution and quick turnaround times. Remote sensing sensors placed on unmanned aerial vehicles (UAVs) could fill this gap, providing low-cost approaches to meet the critical requirements of spatial, spectral, and temporal resolutions. This paper demonstrates the ability to generate quantitative remote sensing products by means of a helicopter-based UAV equipped with inexpensive thermal and narrowband multispectral imaging sensors. During summer of 2007, the platform was flown over agricultural fields, obtaining thermal imagery in the 7.5-13-mum region (40-cm resolution) and narrowband multispectral imagery in the 400-800-nm spectral region (20-cm resolution). Surface reflectance and temperature imagery were obtained, after atmospheric corrections with MODTRAN. Biophysical parameters were estimated using vegetation indices, namely, normalized difference vegetation index, transformed chlorophyll absorption in reflectance index/optimized soil-adjusted vegetation index, and photochemical reflectance index (PRI), coupled with SAILH and FLIGHT models. As a result, the image products of leaf area index, chlorophyll content (C ab), and water stress detection from PRI index and canopy temperature were produced and successfully validated. This paper demonstrates that results obtained with a low-cost UAV system for agricultural applications yielded comparable estimations, if not better, than those obtained by traditional manned airborne sensors.},
	number = {3},
	journal = {IEEE Transactions on Geoscience and Remote Sensing},
	author = {Berni, Jose A. J. and Zarco-Tejada, Pablo J. and Suarez, Lola and Fereres, Elias},
	month = mar,
	year = {2009},
	note = {Conference Name: IEEE Transactions on Geoscience and Remote Sensing},
	keywords = {Reflectivity, Multispectral, Crops, Image resolution, Image sensors, narrowband, Narrowband, radiative transfer modeling, Remote monitoring, remote sensing, Remote sensing, Spatial resolution, stress detection, thermal, unmanned aerial system (UAS), Unmanned aerial vehicles, unmanned aerial vehicles (UAVs), Vegetation mapping},
	pages = {722--738},
	file = {IEEE Xplore Abstract Record:/Users/farhanoktavian/Zotero/storage/YMW6LNSU/4781575.html:text/html;IEEE Xplore Full Text PDF:/Users/farhanoktavian/Zotero/storage/5DZJFWS7/Berni et al. - 2009 - Thermal and Narrowband Multispectral Remote Sensin.pdf:application/pdf},
}

@article{qin_hyperspectral_2013,
	title = {Hyperspectral and multispectral imaging for evaluating food safety and quality},
	volume = {118},
	issn = {0260-8774},
	url = {https://www.sciencedirect.com/science/article/pii/S0260877413001659},
	doi = {10.1016/j.jfoodeng.2013.04.001},
	abstract = {Spectral imaging technologies have been developed rapidly during the past decade. This paper presents hyperspectral and multispectral imaging technologies in the area of food safety and quality evaluation, with an introduction, demonstration, and summarization of current spectral imaging techniques available to the food industry for practical commercial use. The main topics include methods for acquiring spectral images, components for building spectral imaging systems, methods for calibrating spectral imaging systems, and techniques for analyzing spectral images. The applications for evaluating food and agricultural products are presented to reflect common practices of the spectral imaging techniques. Future development of hyperspectral and multispectral imaging is also discussed.},
	language = {en},
	number = {2},
	urldate = {2023-03-03},
	journal = {Journal of Food Engineering},
	author = {Qin, Jianwei and Chao, Kuanglin and Kim, Moon S. and Lu, Renfu and Burks, Thomas F.},
	month = sep,
	year = {2013},
	keywords = {Food quality, Food safety, Hyperspectral, Machine vision, Multispectral, Nondestructive sensing},
	pages = {157--171},
	file = {ScienceDirect Full Text PDF:/Users/farhanoktavian/Zotero/storage/FAJVQWLD/Qin et al. - 2013 - Hyperspectral and multispectral imaging for evalua.pdf:application/pdf;ScienceDirect Snapshot:/Users/farhanoktavian/Zotero/storage/JEZ8RA7B/S0260877413001659.html:text/html},
}

@article{jacques_optical_2013,
	title = {Optical properties of biological tissues: a review},
	volume = {58},
	issn = {0031-9155},
	shorttitle = {Optical properties of biological tissues},
	url = {https://dx.doi.org/10.1088/0031-9155/58/11/R37},
	doi = {10.1088/0031-9155/58/11/R37},
	abstract = {A review of reported tissue optical properties summarizes the wavelength-dependent behavior of scattering and absorption. Formulae are presented for generating the optical properties of a generic tissue with variable amounts of absorbing chromophores (blood, water, melanin, fat, yellow pigments) and a variable balance between small-scale scatterers and large-scale scatterers in the ultrastructures of cells and tissues.},
	language = {en},
	number = {11},
	urldate = {2023-03-03},
	journal = {Physics in Medicine \& Biology},
	author = {Jacques, Steven L.},
	month = may,
	year = {2013},
	note = {Publisher: IOP Publishing},
	pages = {R37},
	file = {IOP Full Text PDF:/Users/farhanoktavian/Zotero/storage/DAHMCDHN/Jacques - 2013 - Optical properties of biological tissues a review.pdf:application/pdf},
}

@article{panasyuk_medical_2007,
	title = {Medical hyperspectral imaging to facilitate residual tumor identification during surgery},
	volume = {6},
	issn = {1538-4047},
	url = {https://doi.org/10.4161/cbt.6.3.4018},
	doi = {10.4161/cbt.6.3.4018},
	abstract = {Introduction: Adequate evaluation of breast tumor resection at surgery continues to be an important issue in surgical care, as over 30\% of postoperative tumors recur locally unless radiation is used to destroy remaining tumor cells in the field. Medical Hyperspectral Imaging (MHSI) delivers near-real time images of biomarkers in tissue, providing an assessment of pathophysiology and the potential to distinguish different tissues based on spectral characteristics.Method: We have used an experimental DMBA-induced rat breast tumor model to examine the intraoperative utility of MHSI, in distinguishing tumor from normal breast and other tissues. Rats bearing tumors underwent surgical exposure and MHSI imaging, followed by partial resection of the tumors, then MHSI imaging of the resection bed, and finally total resection of tumors and of grossly normal-appearing glands. Resected tissue underwent gross examination, MHSI imaging, and histopathological evaluation.Results: An algorithm based on spectral characteristics of tissue types was developed to distinguish between tumor and normal tissues. Tissues including tumor, blood vessels, muscle, and connective tissue were clearly identified and differentiated by MHSI. Fragments of residual tumor 0.5 - 1 mm in size intentionally left in the operative bed were readily identified. MHSI demonstrated a sensitivity of 89\% and a specificity of 94\% for detection of residual tumor, comparable to that of histopathological examination of the tumor bed (85\% and 92\%, respectively).Conclusion: We conclude that MHSI may be useful in identifying small residual tumor in a tumor resection bed and for indicating areas requiring more extensive resection and more effective biopsy locations to the surgeon. 3},
	number = {3},
	urldate = {2023-03-03},
	journal = {Cancer Biology \& Therapy},
	author = {Panasyuk, Svetlana V. and Yang, Shi and Faller, Douglas V. and Ngo, Duyen and Lew, Robert A. and Freeman, Jenny E. and Rogers, Adrianne E.},
	month = mar,
	year = {2007},
	pmid = {17374984},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.4161/cbt.6.3.4018},
	pages = {439--446},
	file = {Full Text PDF:/Users/farhanoktavian/Zotero/storage/E96MX426/Panasyuk et al. - 2007 - Medical hyperspectral imaging to facilitate residu.pdf:application/pdf},
}

@inproceedings{randeberg_hyperspectral_2006,
	title = {Hyperspectral imaging of bruised skin},
	volume = {6078},
	url = {https://www.spiedigitallibrary.org/conference-proceedings-of-spie/6078/60780O/Hyperspectral-imaging-of-bruised-skin/10.1117/12.646557.full},
	doi = {10.1117/12.646557},
	abstract = {Bruises can be important evidence in legal medicine, for example in cases of child abuse. Optical techniques can be used to discriminate and quantify the chromophores present in bruised skin, and thereby aid dating of an injury. However, spectroscopic techniques provide only average chromophore concentrations for the sampled volume, and contain little information about the spatial chromophore distribution in the bruise. Hyperspectral imaging combines the power of imaging and spectroscopy, and can provide both spectroscopic and spatial information. In this study a hyperspectral imaging system developed by Norsk Elektro Optikk AS was used to measure the temporal development of bruised skin in a human volunteer. The bruises were inflicted by paintball bullets. The wavelength ranges used were 400 - 1000 nm (VNIR) and 900 - 1700 nm (SWIR), and the spectral sampling intervals were 3.7 and 5 nm, respectively. Preliminary results show good spatial discrimination of the bruised areas compared to normal skin. Development of a white spot can be seen in the central zone of the bruises. This central white zone was found to resemble the shape of the object hitting the skin, and is believed to develop in areas where the impact caused vessel damage. These results show that hyperspectral imaging is a promising technique to evaluate the temporal and spatial development of bruises on human skin.},
	urldate = {2023-03-03},
	booktitle = {Photonic {Therapeutics} and {Diagnostics} {II}},
	publisher = {SPIE},
	author = {Randeberg, Lise L. and Baarstad, Ivar and Løke, Trond and Kaspersen, Peter and Svaasand, Lars O.},
	month = feb,
	year = {2006},
	pages = {100--110},
	file = {Full Text PDF:/Users/farhanoktavian/Zotero/storage/V987I7TJ/Randeberg et al. - 2006 - Hyperspectral imaging of bruised skin.pdf:application/pdf},
}

@inproceedings{hashimoto_tissue_2017,
	title = {Tissue classification of liver pathological tissue specimens image using spectral features},
	volume = {10140},
	url = {https://www.spiedigitallibrary.org/conference-proceedings-of-spie/10140/101400Z/Tissue-classification-of-liver-pathological-tissue-specimens-image-using-spectral/10.1117/12.2253818.full},
	doi = {10.1117/12.2253818},
	abstract = {In digital pathology diagnosis, accurate recognition and quantification of the tissue structure is an important factor for computer-aided diagnosis. However, the classification accuracy of cytoplasm is low in Hematoxylin and eosin (HE) stained liver pathology specimens because the RGB color values of cytoplasm are almost similar to that of fibers. In this paper, we propose a new tissue classification method for HE stained liver pathology specimens by using hyperspectral image. At first we select valid spectra from the image to make a clear distinction between fibers and cytoplasm, and then classify five types of tissue based on the bag of features (BoF). The average classification accuracy for all tissues was improved by 11\% in the case of using BoF of RGB and selected spectra bands in comparison with using only RGB. In particular, the improvement reached to 24\% for fibers and 5\% for cytoplasm.},
	urldate = {2023-03-03},
	booktitle = {Medical {Imaging} 2017: {Digital} {Pathology}},
	publisher = {SPIE},
	author = {Hashimoto, Emi and Ishikawa, Masahiro and Shinoda, Kazuma and Hasegawa, Madoka and Komagata, Hideki and Kobayashi, Naoki and Mochidome, Naoki and Oda, Yoshinao and Iwamoto, Chika and Ohuchida, Kenoki and Hashizume, Makoto},
	month = mar,
	year = {2017},
	pages = {243--248},
	file = {Full Text PDF:/Users/farhanoktavian/Zotero/storage/PHSNQQMC/Hashimoto et al. - 2017 - Tissue classification of liver pathological tissue.pdf:application/pdf},
}

@article{ortega_hyperspectral_2020-1,
	title = {Hyperspectral and multispectral imaging in digital and computational pathology: a systematic review [{Invited}]},
	volume = {11},
	copyright = {© 2020 Optical Society of America},
	issn = {2156-7085},
	shorttitle = {Hyperspectral and multispectral imaging in digital and computational pathology},
	url = {https://opg.optica.org/boe/abstract.cfm?uri=boe-11-6-3195},
	doi = {10.1364/BOE.386338},
	abstract = {Hyperspectral imaging (HSI) and multispectral imaging (MSI) technologies have the potential to transform the fields of digital and computational pathology. Traditional digitized histopathological slides are imaged with RGB imaging. Utilizing HSI/MSI, spectral information across wavelengths within and beyond the visual range can complement spatial information for the creation of computer-aided diagnostic tools for both stained and unstained histological specimens. In this systematic review, we summarize the methods and uses of HSI/MSI for staining and color correction, immunohistochemistry, autofluorescence, and histopathological diagnostic research. Studies include hematology, breast cancer, head and neck cancer, skin cancer, and diseases of central nervous, gastrointestinal, and genitourinary systems. The use of HSI/MSI suggest an improvement in the detection of diseases and clinical practice compared with traditional RGB analysis, and brings new opportunities in histological analysis of samples, such as digital staining or alleviating the inter-laboratory variability of digitized samples. Nevertheless, the number of studies in this field is currently limited, and more research is needed to confirm the advantages of this technology compared to conventional imagery.},
	language = {EN},
	number = {6},
	urldate = {2023-03-03},
	journal = {Biomedical Optics Express},
	author = {Ortega, Samuel and Halicek, Martin and Fabelo, Himar and Callico, Gustavo M. and Fei, Baowei},
	month = jun,
	year = {2020},
	note = {Publisher: Optica Publishing Group},
	keywords = {Hyperspectral imaging, Multispectral imaging, Image processing, Imaging spectroscopy, Imaging techniques, Light propagation},
	pages = {3195--3233},
	file = {Full Text PDF:/Users/farhanoktavian/Zotero/storage/QWDM2BAE/Ortega et al. - 2020 - Hyperspectral and multispectral imaging in digital.pdf:application/pdf},
}

@misc{cruk_brain_2023,
	title = {Brain tumours},
	url = {https://www.cancerresearchuk.org/about-cancer/brain-tumours},
	abstract = {Primary brain tumours are cancers that start in the brain.},
	language = {en},
	urldate = {2023-02-25},
	journal = {Cancer Research UK},
	author = {CRUK},
	month = jan,
	year = {2023},
	file = {Snapshot:/Users/farhanoktavian/Zotero/storage/5VYILABJ/brain-tumours.html:text/html},
}

@article{gerard_brain_2017,
	title = {Brain shift in neuronavigation of brain tumors: {A} review},
	volume = {35},
	issn = {1361-8415},
	shorttitle = {Brain shift in neuronavigation of brain tumors},
	url = {https://www.sciencedirect.com/science/article/pii/S1361841516301566},
	doi = {10.1016/j.media.2016.08.007},
	abstract = {Purpose: Neuronavigation based on preoperative imaging data is a ubiquitous tool for image guidance in neurosurgery. However, it is rendered unreliable when brain shift invalidates the patient-to-image registration. Many investigators have tried to explain, quantify, and compensate for this phenomenon to allow extended use of neuronavigation systems for the duration of surgery. The purpose of this paper is to present an overview of the work that has been done investigating brain shift. Methods: A review of the literature dealing with the explanation, quantification and compensation of brain shift is presented. The review is based on a systematic search using relevant keywords and phrases in PubMed. The review is organized based on a developed taxonomy that classifies brain shift as occurring due to physical, surgical or biological factors. Results: This paper gives an overview of the work investigating, quantifying, and compensating for brain shift in neuronavigation while describing the successes, setbacks, and additional needs in the field. An analysis of the literature demonstrates a high variability in the methods used to quantify brain shift as well as a wide range in the measured magnitude of the brain shift, depending on the specifics of the intervention. The analysis indicates the need for additional research to be done in quantifying independent effects of brain shift in order for some of the state of the art compensation methods to become useful. Conclusion: This review allows for a thorough understanding of the work investigating brain shift and introduces the needs for future avenues of investigation of the phenomenon.},
	language = {en},
	urldate = {2023-03-03},
	journal = {Medical Image Analysis},
	author = {Gerard, Ian J. and Kersten-Oertel, Marta and Petrecca, Kevin and Sirhan, Denis and Hall, Jeffery A. and Collins, D. Louis},
	month = jan,
	year = {2017},
	keywords = {Brain shift, Image guided neurosurgery, Intraoperative imaging, Neuronavigation, Registration errors},
	pages = {403--420},
	file = {ScienceDirect Full Text PDF:/Users/farhanoktavian/Zotero/storage/IQDRYCLS/Gerard et al. - 2017 - Brain shift in neuronavigation of brain tumors A .pdf:application/pdf;ScienceDirect Snapshot:/Users/farhanoktavian/Zotero/storage/HA6BNATV/S1361841516301566.html:text/html},
}

@article{nguyen_hyperspectral_2019,
	title = {Hyperspectral near-infrared spectroscopy assessment of the brain during hypoperfusion},
	volume = {24},
	issn = {1083-3668, 1560-2281},
	url = {https://www.spiedigitallibrary.org/journals/journal-of-biomedical-optics/volume-24/issue-3/035007/Hyperspectral-near-infrared-spectroscopy-assessment-of-the-brain-during-hypoperfusion/10.1117/1.JBO.24.3.035007.full},
	doi = {10.1117/1.JBO.24.3.035007},
	abstract = {Two-thirds of out-of-hospital cardiac arrest patients, who survive to hospital admission, die in the hospital from neurological injuries related to cerebral hypoperfusion. Therefore, noninvasive real-time monitoring of the cerebral oxygen metabolism in cardiac arrest patients is extremely important. Hyperspectral near-infrared spectroscopy (hNIRS) is a noninvasive technique that measures concentrations of the key chromophores in the brain, such as oxygenated hemoglobin, deoxygenated hemoglobin, and cytochrome C oxidase (CCO), an intracellular marker of oxygen consumption. We tested hNIRS on 10 patients undergoing transcatheter aortic valve insertion, where rapid ventricular pacing (RVP) is required to temporarily induce sudden hypotension and hypoperfusion that mimic cardiac arrest. Using multidistance hNIRS, we found that tissue oxygen saturation changes in the cerebral tissue were lower than those in the scalp during RVP. CCO redox changes were detected in cerebral tissue but not in the scalp during RVP. We have demonstrated that hNIRS is feasible and can detect sudden changes in cerebral oxygenation and metabolism in patients during profound hypotension.},
	number = {3},
	urldate = {2023-03-03},
	journal = {Journal of Biomedical Optics},
	author = {Nguyen, Thu Nga and Wu, Wen and Woldemichael, Ermias and Toronov, Vladislav and Lin, Steve},
	month = mar,
	year = {2019},
	note = {Publisher: SPIE},
	pages = {035007},
	file = {Full Text PDF:/Users/farhanoktavian/Zotero/storage/4TSJXZ2E/Nguyen et al. - 2019 - Hyperspectral near-infrared spectroscopy assessmen.pdf:application/pdf},
}

@inproceedings{vaswani_attention_2017,
	title = {Attention is {All} you {Need}},
	volume = {30},
	url = {https://proceedings.neurips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html},
	abstract = {The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.},
	urldate = {2023-03-03},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, Łukasz and Polosukhin, Illia},
	year = {2017},
	file = {Full Text PDF:/Users/farhanoktavian/Zotero/storage/BQSSQ2IG/Vaswani et al. - 2017 - Attention is All you Need.pdf:application/pdf},
}

@article{bioucas-dias_hyperspectral_2008,
	title = {Hyperspectral {Subspace} {Identification}},
	volume = {46},
	issn = {1558-0644},
	doi = {10.1109/TGRS.2008.918089},
	abstract = {Signal subspace identification is a crucial first step in many hyperspectral processing algorithms such as target detection, change detection, classification, and unmixing. The identification of this subspace enables a correct dimensionality reduction, yielding gains in algorithm performance and complexity and in data storage. This paper introduces a new minimum mean square error-based approach to infer the signal subspace in hyperspectral imagery. The method, which is termed hyperspectral signal identification by minimum error, is eigen decomposition based, unsupervised, and fully automatic (i.e., it does not depend on any tuning parameters). It first estimates the signal and noise correlation matrices and then selects the subset of eigenvalues that best represents the signal subspace in the least squared error sense. State-of-the-art performance of the proposed method is illustrated by using simulated and real hyperspectral images.},
	number = {8},
	journal = {IEEE Transactions on Geoscience and Remote Sensing},
	author = {Bioucas-Dias, JosÉ M. and Nascimento, JosÉ M. P.},
	month = aug,
	year = {2008},
	note = {Conference Name: IEEE Transactions on Geoscience and Remote Sensing},
	keywords = {Hyperspectral imaging, Change detection algorithms, Dimensionality reduction, Eigenvalues and eigenfunctions, hyperspectral imagery, Hyperspectral sensors, hyperspectral signal subspace identification by minimum error (HySime), hyperspectral unmixing, linear mixture, Matrix decomposition, Memory, minimum mean square error (mse), Object detection, Parameter estimation, Performance gain, Signal processing, subspace identification},
	pages = {2435--2445},
	file = {IEEE Xplore Abstract Record:/Users/farhanoktavian/Zotero/storage/BM6HMJWI/stamp.html:text/html;IEEE Xplore Full Text PDF:/Users/farhanoktavian/Zotero/storage/N2KCPJN3/Bioucas-Dias and Nascimento - 2008 - Hyperspectral Subspace Identification.pdf:application/pdf},
}

@misc{kirillov_segment_2023,
	title = {Segment {Anything}},
	url = {http://arxiv.org/abs/2304.02643},
	doi = {10.48550/arXiv.2304.02643},
	abstract = {We introduce the Segment Anything (SA) project: a new task, model, and dataset for image segmentation. Using our efficient model in a data collection loop, we built the largest segmentation dataset to date (by far), with over 1 billion masks on 11M licensed and privacy respecting images. The model is designed and trained to be promptable, so it can transfer zero-shot to new image distributions and tasks. We evaluate its capabilities on numerous tasks and find that its zero-shot performance is impressive -- often competitive with or even superior to prior fully supervised results. We are releasing the Segment Anything Model (SAM) and corresponding dataset (SA-1B) of 1B masks and 11M images at https://segment-anything.com to foster research into foundation models for computer vision.},
	urldate = {2023-04-11},
	publisher = {arXiv},
	author = {Kirillov, Alexander and Mintun, Eric and Ravi, Nikhila and Mao, Hanzi and Rolland, Chloe and Gustafson, Laura and Xiao, Tete and Whitehead, Spencer and Berg, Alexander C. and Lo, Wan-Yen and Dollár, Piotr and Girshick, Ross},
	month = apr,
	year = {2023},
	note = {arXiv:2304.02643 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	file = {arXiv Fulltext PDF:/Users/farhanoktavian/Zotero/storage/88IPXS4N/Kirillov et al. - 2023 - Segment Anything.pdf:application/pdf;arXiv.org Snapshot:/Users/farhanoktavian/Zotero/storage/GF2BIMDK/2304.html:text/html},
}

@article{pilet_fast_2008,
	title = {Fast {Non}-{Rigid} {Surface} {Detection}, {Registration} and {Realistic} {Augmentation}},
	volume = {76},
	issn = {1573-1405},
	url = {https://doi.org/10.1007/s11263-006-0017-9},
	doi = {10.1007/s11263-006-0017-9},
	abstract = {We present a real-time method for detecting deformable surfaces, with no need whatsoever for a priori pose knowledge.},
	language = {en},
	number = {2},
	urldate = {2023-05-23},
	journal = {International Journal of Computer Vision},
	author = {Pilet, Julien and Lepetit, Vincent and Fua, Pascal},
	month = feb,
	year = {2008},
	keywords = {Non-rigid augmented reality, Non-rigid detection, Real-time deformable registration},
	pages = {109--122},
	file = {Full Text PDF:/Users/farhanoktavian/Zotero/storage/BSZRP9QI/Pilet et al. - 2008 - Fast Non-Rigid Surface Detection, Registration and.pdf:application/pdf},
}

@article{du_robust_2015,
	title = {Robust surface tracking combining features, intensity and illumination compensation},
	volume = {10},
	issn = {1861-6429},
	url = {https://doi.org/10.1007/s11548-015-1243-9},
	doi = {10.1007/s11548-015-1243-9},
	abstract = {Recovering tissue deformation during robotic-assisted minimally invasive surgery procedures is important for providing intra-operative guidance, enabling in vivo imaging modalities and enhanced robotic control. The tissue motion can also be used to apply motion stabilization and to prescribe dynamic constraints for avoiding critical anatomical structures.},
	language = {en},
	number = {12},
	urldate = {2023-06-13},
	journal = {International Journal of Computer Assisted Radiology and Surgery},
	author = {Du, Xiaofei and Clancy, Neil and Arya, Shobhit and Hanna, George B. and Kelly, John and Elson, Daniel S. and Stoyanov, Danail},
	month = dec,
	year = {2015},
	keywords = {Minimally invasive surgery, Multispectral imaging, Illumination compensation, Non-rigid surface tracking},
	pages = {1915--1926},
	file = {Full Text PDF:/Users/farhanoktavian/Zotero/storage/9MT2HKDV/Du et al. - 2015 - Robust surface tracking combining features, intens.pdf:application/pdf},
}

@article{yang_fast_2008,
	title = {A fast inverse consistent deformable image registration method based on symmetric optical flow computation},
	volume = {53},
	issn = {0031-9155},
	url = {https://dx.doi.org/10.1088/0031-9155/53/21/017},
	doi = {10.1088/0031-9155/53/21/017},
	abstract = {Deformable image registration is widely used in various radiation therapy applications including daily treatment planning adaptation to map planned tissue or dose to changing anatomy. In this work, a simple and efficient inverse consistency deformable registration method is proposed with aims of higher registration accuracy and faster convergence speed. Instead of registering image I to a second image J, the two images are symmetrically deformed toward one another in multiple passes, until both deformed images are matched and correct registration is therefore achieved. In each pass, a delta motion field is computed by minimizing a symmetric optical flow system cost function using modified optical flow algorithms. The images are then further deformed with the delta motion field in the positive and negative directions respectively, and then used for the next pass. The magnitude of the delta motion field is forced to be less than 0.4 voxel for every pass in order to guarantee smoothness and invertibility for the two overall motion fields that are accumulating the delta motion fields in both positive and negative directions, respectively. The final motion fields to register the original images I and J, in either direction, are calculated by inverting one overall motion field and combining the inversion result with the other overall motion field. The final motion fields are inversely consistent and this is ensured by the symmetric way that registration is carried out. The proposed method is demonstrated with phantom images, artificially deformed patient images and 4D-CT images. Our results suggest that the proposed method is able to improve the overall accuracy (reducing registration error by 30\% or more, compared to the original and inversely inconsistent optical flow algorithms), reduce the inverse consistency error (by 95\% or more) and increase the convergence rate (by 100\% or more). The overall computation speed may slightly decrease, or increase in most cases because the new method converges faster. Compared to previously reported inverse consistency algorithms, the proposed method is simpler, easier to implement and more efficient.},
	language = {en},
	number = {21},
	urldate = {2023-06-13},
	journal = {Physics in Medicine \& Biology},
	author = {Yang, Deshan and Li, Hua and Low, Daniel A. and Deasy, Joseph O. and Naqa, Issam El},
	month = oct,
	year = {2008},
	pages = {6143},
	file = {IOP Full Text PDF:/Users/farhanoktavian/Zotero/storage/AAP6JQRR/Yang et al. - 2008 - A fast inverse consistent deformable image registr.pdf:application/pdf},
}

@article{xue_gradient_2014,
	title = {Gradient {Magnitude} {Similarity} {Deviation}: {A} {Highly} {Efficient} {Perceptual} {Image} {Quality} {Index}},
	volume = {23},
	issn = {1941-0042},
	shorttitle = {Gradient {Magnitude} {Similarity} {Deviation}},
	doi = {10.1109/TIP.2013.2293423},
	abstract = {It is an important task to faithfully evaluate the perceptual quality of output images in many applications, such as image compression, image restoration, and multimedia streaming. A good image quality assessment (IQA) model should not only deliver high quality prediction accuracy, but also be computationally efficient. The efficiency of IQA metrics is becoming particularly important due to the increasing proliferation of high-volume visual data in high-speed networks. We present a new effective and efficient IQA model, called gradient magnitude similarity deviation (GMSD). The image gradients are sensitive to image distortions, while different local structures in a distorted image suffer different degrees of degradations. This motivates us to explore the use of global variation of gradient based local quality map for overall image quality prediction. We find that the pixel-wise gradient magnitude similarity (GMS) between the reference and distorted images combined with a novel pooling strategy-the standard deviation of the GMS map-can predict accurately perceptual image quality. The resulting GMSD algorithm is much faster than most state-of-the-art IQA methods, and delivers highly competitive prediction accuracy. MATLAB source code of GMSD can be downloaded at http://www4.comp.polyu.edu.hk/ cslzhang/IQA/GMSD/GMSD.htm.},
	number = {2},
	journal = {IEEE Transactions on Image Processing},
	author = {Xue, Wufeng and Zhang, Lei and Mou, Xuanqin and Bovik, Alan C.},
	month = feb,
	year = {2014},
	note = {Conference Name: IEEE Transactions on Image Processing},
	keywords = {Computational modeling, Accuracy, Degradation, full reference, Gradient magnitude similarity, Image coding, Image quality, image quality assessment, Indexes, Nonlinear distortion, standard deviation pooling},
	pages = {684--695},
	file = {IEEE Xplore Abstract Record:/Users/farhanoktavian/Zotero/storage/WX9H4YZ5/6678238.html:text/html;IEEE Xplore Full Text PDF:/Users/farhanoktavian/Zotero/storage/WFUYUBK7/Xue et al. - 2014 - Gradient Magnitude Similarity Deviation A Highly .pdf:application/pdf},
}

@article{zhu_fast_2009,
	title = {A {Fast} {2D} {Shape} {Recovery} {Approach} by {Fusing} {Features} and {Appearance}},
	volume = {31},
	issn = {1939-3539},
	doi = {10.1109/TPAMI.2008.151},
	abstract = {In this paper, we present a fusion approach to solve the nonrigid shape recovery problem, which takes advantage of both the appearance information and the local features. We have two major contributions. First, we propose a novel progressive finite Newton optimization scheme for the feature-based nonrigid surface detection problem, which is reduced to only solving a set of linear equations. The key is to formulate the nonrigid surface detection as an unconstrained quadratic optimization problem that has a closed-form solution for a given set of observations. Second, we propose a deformable Lucas-Kanade algorithm that triangulates the template image into small patches and constrains the deformation through the second-order derivatives of the mesh vertices. We formulate it into a sparse regularized least squares problem, which is able to reduce the computational cost and the memory requirement. The inverse compositional algorithm is applied to efficiently solve the optimization problem. We have conducted extensive experiments for performance evaluation on various environments, whose promising results show that the proposed algorithm is both efficient and effective.},
	number = {7},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Zhu, Jianke and Lyu, Michael R. and Huang, Thomas S.},
	month = jul,
	year = {2009},
	note = {Conference Name: IEEE Transactions on Pattern Analysis and Machine Intelligence},
	keywords = {Computer vision, Object detection, Augmented reality, Biomedical imaging, Closed-form solution, Computational efficiency, Equations, Image processing and computer vision, Image registration, Least squares methods, medical image registration., Modeling and recovery of physical attributes, nonrigid augmented reality, nonrigid detection, real-time deformable registration, Shape, Video analysis},
	pages = {1210--1224},
	file = {IEEE Xplore Abstract Record:/Users/farhanoktavian/Zotero/storage/YFMZ6KD5/4540099.html:text/html;IEEE Xplore Full Text PDF:/Users/farhanoktavian/Zotero/storage/EB52QBCR/Zhu et al. - 2009 - A Fast 2D Shape Recovery Approach by Fusing Featur.pdf:application/pdf},
}

@misc{liu_convnet_2022,
	title = {A {ConvNet} for the 2020s},
	url = {http://arxiv.org/abs/2201.03545},
	doi = {10.48550/arXiv.2201.03545},
	abstract = {The "Roaring 20s" of visual recognition began with the introduction of Vision Transformers (ViTs), which quickly superseded ConvNets as the state-of-the-art image classification model. A vanilla ViT, on the other hand, faces difficulties when applied to general computer vision tasks such as object detection and semantic segmentation. It is the hierarchical Transformers (e.g., Swin Transformers) that reintroduced several ConvNet priors, making Transformers practically viable as a generic vision backbone and demonstrating remarkable performance on a wide variety of vision tasks. However, the effectiveness of such hybrid approaches is still largely credited to the intrinsic superiority of Transformers, rather than the inherent inductive biases of convolutions. In this work, we reexamine the design spaces and test the limits of what a pure ConvNet can achieve. We gradually "modernize" a standard ResNet toward the design of a vision Transformer, and discover several key components that contribute to the performance difference along the way. The outcome of this exploration is a family of pure ConvNet models dubbed ConvNeXt. Constructed entirely from standard ConvNet modules, ConvNeXts compete favorably with Transformers in terms of accuracy and scalability, achieving 87.8\% ImageNet top-1 accuracy and outperforming Swin Transformers on COCO detection and ADE20K segmentation, while maintaining the simplicity and efficiency of standard ConvNets.},
	urldate = {2023-06-19},
	publisher = {arXiv},
	author = {Liu, Zhuang and Mao, Hanzi and Wu, Chao-Yuan and Feichtenhofer, Christoph and Darrell, Trevor and Xie, Saining},
	month = mar,
	year = {2022},
	note = {arXiv:2201.03545 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:/Users/farhanoktavian/Zotero/storage/HTDR3FU4/Liu et al. - 2022 - A ConvNet for the 2020s.pdf:application/pdf;arXiv.org Snapshot:/Users/farhanoktavian/Zotero/storage/FHLV8H5Q/2201.html:text/html},
}

@article{balakrishnan_voxelmorph_2019,
	title = {{VoxelMorph}: {A} {Learning} {Framework} for {Deformable} {Medical} {Image} {Registration}},
	volume = {38},
	issn = {0278-0062, 1558-254X},
	shorttitle = {{VoxelMorph}},
	url = {http://arxiv.org/abs/1809.05231},
	doi = {10.1109/TMI.2019.2897538},
	abstract = {We present VoxelMorph, a fast learning-based framework for deformable, pairwise medical image registration. Traditional registration methods optimize an objective function for each pair of images, which can be time-consuming for large datasets or rich deformation models. In contrast to this approach, and building on recent learning-based methods, we formulate registration as a function that maps an input image pair to a deformation field that aligns these images. We parameterize the function via a convolutional neural network (CNN), and optimize the parameters of the neural network on a set of images. Given a new pair of scans, VoxelMorph rapidly computes a deformation field by directly evaluating the function. In this work, we explore two different training strategies. In the first (unsupervised) setting, we train the model to maximize standard image matching objective functions that are based on the image intensities. In the second setting, we leverage auxiliary segmentations available in the training data. We demonstrate that the unsupervised model's accuracy is comparable to state-of-the-art methods, while operating orders of magnitude faster. We also show that VoxelMorph trained with auxiliary data improves registration accuracy at test time, and evaluate the effect of training set size on registration. Our method promises to speed up medical image analysis and processing pipelines, while facilitating novel directions in learning-based registration and its applications. Our code is freely available at voxelmorph.csail.mit.edu.},
	number = {8},
	urldate = {2023-06-19},
	journal = {IEEE Transactions on Medical Imaging},
	author = {Balakrishnan, Guha and Zhao, Amy and Sabuncu, Mert R. and Guttag, John and Dalca, Adrian V.},
	month = aug,
	year = {2019},
	note = {arXiv:1809.05231 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	pages = {1788--1800},
	file = {arXiv Fulltext PDF:/Users/farhanoktavian/Zotero/storage/EUUIB526/Balakrishnan et al. - 2019 - VoxelMorph A Learning Framework for Deformable Me.pdf:application/pdf;arXiv.org Snapshot:/Users/farhanoktavian/Zotero/storage/V486GFLG/1809.html:text/html},
}

@article{zhang_bcu-net_2023,
	title = {{BCU}-{Net}: {Bridging} {ConvNeXt} and {U}-{Net} for medical image segmentation},
	volume = {159},
	issn = {0010-4825},
	shorttitle = {{BCU}-{Net}},
	url = {https://www.sciencedirect.com/science/article/pii/S0010482523004250},
	doi = {10.1016/j.compbiomed.2023.106960},
	abstract = {Medical image segmentation enables doctors to observe lesion regions better and make accurate diagnostic decisions. Single-branch models such as U-Net have achieved great progress in this field. However, the complementary local and global pathological semantics of heterogeneous neural networks have not yet been fully explored. The class-imbalance problem remains a serious issue. To alleviate these two problems, we propose a novel model called BCU-Net, which leverages the advantages of ConvNeXt in global interaction and U-Net in local processing. We propose a new multilabel recall loss (MRL) module to relieve the class imbalance problem and facilitate deep-level fusion of local and global pathological semantics between the two heterogeneous branches. Extensive experiments were conducted on six medical image datasets including retinal vessel and polyp images. The qualitative and quantitative results demonstrate the superiority and generalizability of BCU-Net. In particular, BCU-Net can handle diverse medical images with diverse resolutions. It has a flexible structure owing to its plug-and-play characteristics, which promotes its practicality.},
	language = {en},
	urldate = {2023-08-01},
	journal = {Computers in Biology and Medicine},
	author = {Zhang, Hongbin and Zhong, Xiang and Li, Guangli and Liu, Wei and Liu, Jiawei and Ji, Donghong and Li, Xiong and Wu, Jianguo},
	month = jun,
	year = {2023},
	keywords = {Class imbalance, ConvNeXt, Medical image segmentation, Multi-label recall loss, U-Net},
	pages = {106960},
	file = {ScienceDirect Full Text PDF:/Users/farhanoktavian/Zotero/storage/652PPG2C/Zhang et al. - 2023 - BCU-Net Bridging ConvNeXt and U-Net for medical i.pdf:application/pdf;ScienceDirect Snapshot:/Users/farhanoktavian/Zotero/storage/RC3M5RLR/S0010482523004250.html:text/html},
}

@misc{shen_ransac-flow_2020,
	title = {{RANSAC}-{Flow}: generic two-stage image alignment},
	shorttitle = {{RANSAC}-{Flow}},
	url = {http://arxiv.org/abs/2004.01526},
	doi = {10.48550/arXiv.2004.01526},
	abstract = {This paper considers the generic problem of dense alignment between two images, whether they be two frames of a video, two widely different views of a scene, two paintings depicting similar content, etc. Whereas each such task is typically addressed with a domain-specific solution, we show that a simple unsupervised approach performs surprisingly well across a range of tasks. Our main insight is that parametric and non-parametric alignment methods have complementary strengths. We propose a two-stage process: first, a feature-based parametric coarse alignment using one or more homographies, followed by non-parametric fine pixel-wise alignment. Coarse alignment is performed using RANSAC on off-the-shelf deep features. Fine alignment is learned in an unsupervised way by a deep network which optimizes a standard structural similarity metric (SSIM) between the two images, plus cycle-consistency. Despite its simplicity, our method shows competitive results on a range of tasks and datasets, including unsupervised optical flow on KITTI, dense correspondences on Hpatches, two-view geometry estimation on YFCC100M, localization on Aachen Day-Night, and, for the first time, fine alignment of artworks on the Brughel dataset. Our code and data are available at http://imagine.enpc.fr/{\textasciitilde}shenx/RANSAC-Flow/},
	urldate = {2023-09-04},
	publisher = {arXiv},
	author = {Shen, Xi and Darmon, François and Efros, Alexei A. and Aubry, Mathieu},
	month = jul,
	year = {2020},
	note = {arXiv:2004.01526 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:/Users/farhanoktavian/Zotero/storage/GDLZ8RF6/Shen et al. - 2020 - RANSAC-Flow generic two-stage image alignment.pdf:application/pdf;arXiv.org Snapshot:/Users/farhanoktavian/Zotero/storage/KGSHIWMF/2004.html:text/html},
}

@misc{simonyan_very_2015,
	title = {Very {Deep} {Convolutional} {Networks} for {Large}-{Scale} {Image} {Recognition}},
	url = {http://arxiv.org/abs/1409.1556},
	doi = {10.48550/arXiv.1409.1556},
	abstract = {In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.},
	urldate = {2023-09-04},
	publisher = {arXiv},
	author = {Simonyan, Karen and Zisserman, Andrew},
	month = apr,
	year = {2015},
	note = {arXiv:1409.1556 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:/Users/farhanoktavian/Zotero/storage/A5EXKPZ9/Simonyan and Zisserman - 2015 - Very Deep Convolutional Networks for Large-Scale I.pdf:application/pdf;arXiv.org Snapshot:/Users/farhanoktavian/Zotero/storage/3S9P7V7T/1409.html:text/html},
}

@inproceedings{chen_xgboost_2016,
	title = {{XGBoost}: {A} {Scalable} {Tree} {Boosting} {System}},
	shorttitle = {{XGBoost}},
	url = {http://arxiv.org/abs/1603.02754},
	doi = {10.1145/2939672.2939785},
	abstract = {Tree boosting is a highly effective and widely used machine learning method. In this paper, we describe a scalable end-to-end tree boosting system called XGBoost, which is used widely by data scientists to achieve state-of-the-art results on many machine learning challenges. We propose a novel sparsity-aware algorithm for sparse data and weighted quantile sketch for approximate tree learning. More importantly, we provide insights on cache access patterns, data compression and sharding to build a scalable tree boosting system. By combining these insights, XGBoost scales beyond billions of examples using far fewer resources than existing systems.},
	urldate = {2023-09-04},
	booktitle = {Proceedings of the 22nd {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} and {Data} {Mining}},
	author = {Chen, Tianqi and Guestrin, Carlos},
	month = aug,
	year = {2016},
	note = {arXiv:1603.02754 [cs]},
	keywords = {Computer Science - Machine Learning},
	pages = {785--794},
	file = {arXiv Fulltext PDF:/Users/farhanoktavian/Zotero/storage/LSW4JZ2X/Chen and Guestrin - 2016 - XGBoost A Scalable Tree Boosting System.pdf:application/pdf;arXiv.org Snapshot:/Users/farhanoktavian/Zotero/storage/DTQRQAJ6/1603.html:text/html},
}

@article{clancy_surgical_2020,
	title = {Surgical spectral imaging},
	volume = {63},
	issn = {1361-8415},
	url = {https://www.sciencedirect.com/science/article/pii/S1361841520300645},
	doi = {10.1016/j.media.2020.101699},
	abstract = {Recent technological developments have resulted in the availability of miniaturised spectral imaging sensors capable of operating in the multi- (MSI) and hyperspectral imaging (HSI) regimes. Simultaneous advances in image-processing techniques and artificial intelligence (AI), especially in machine learning and deep learning, have made these data-rich modalities highly attractive as a means of extracting biological information non-destructively. Surgery in particular is poised to benefit from this, as spectrally-resolved tissue optical properties can offer enhanced contrast as well as diagnostic and guidance information during interventions. This is particularly relevant for procedures where inherent contrast is low under standard white light visualisation. This review summarises recent work in surgical spectral imaging (SSI) techniques, taken from Pubmed, Google Scholar and arXiv searches spanning the period 2013–2019. New hardware, optimised for use in both open and minimally-invasive surgery (MIS), is described, and recent commercial activity is summarised. Computational approaches to extract spectral information from conventional colour images are reviewed, as tip-mounted cameras become more commonplace in MIS. Model-based and machine learning methods of data analysis are discussed in addition to simulation, phantom and clinical validation experiments. A wide variety of surgical pilot studies are reported but it is apparent that further work is needed to quantify the clinical value of MSI/HSI. The current trend toward data-driven analysis emphasises the importance of widely-available, standardised spectral imaging datasets, which will aid understanding of variability across organs and patients, and drive clinical translation.},
	urldate = {2023-09-08},
	journal = {Medical Image Analysis},
	author = {Clancy, Neil T. and Jones, Geoffrey and Maier-Hein, Lena and Elson, Daniel S. and Stoyanov, Danail},
	month = jul,
	year = {2020},
	keywords = {Computational imaging, Hyperspectral imaging, Minimally-invasive surgery, Multispectral imaging},
	pages = {101699},
	file = {ScienceDirect Full Text PDF:/Users/farhanoktavian/Zotero/storage/VG3MVMJD/Clancy et al. - 2020 - Surgical spectral imaging.pdf:application/pdf;ScienceDirect Snapshot:/Users/farhanoktavian/Zotero/storage/CHPNS9HB/S1361841520300645.html:text/html},
}

@article{oliveira_medical_2014,
	title = {Medical image registration: a review},
	volume = {17},
	issn = {1025-5842},
	shorttitle = {Medical image registration},
	url = {https://doi.org/10.1080/10255842.2012.670855},
	doi = {10.1080/10255842.2012.670855},
	abstract = {This paper presents a review of automated image registration methodologies that have been used in the medical field. The aim of this paper is to be an introduction to the field, provide knowledge on the work that has been developed and to be a suitable reference for those who are looking for registration methods for a specific application. The registration methodologies under review are classified into intensity or feature based. The main steps of these methodologies, the common geometric transformations, the similarity measures and accuracy assessment techniques are introduced and described.},
	number = {2},
	urldate = {2023-09-11},
	journal = {Computer Methods in Biomechanics and Biomedical Engineering},
	author = {Oliveira, Francisco P.M. and Tavares, João Manuel R.S.},
	month = jan,
	year = {2014},
	pmid = {22435355},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/10255842.2012.670855},
	keywords = {computational methods, geometrical transformations, image alignment, matching, warping, image analysis, optimisation, similarity measures},
	pages = {73--93},
	file = {Full Text PDF:/Users/farhanoktavian/Zotero/storage/6AS2T7XB/Oliveira and Tavares - 2014 - Medical image registration a review.pdf:application/pdf},
}

@article{wang_medical_2022,
	title = {Medical image segmentation using deep learning: {A} survey},
	volume = {16},
	copyright = {© 2022 The Authors. IET Image Processing published by John Wiley \& Sons Ltd on behalf of The Institution of Engineering and Technology},
	issn = {1751-9667},
	shorttitle = {Medical image segmentation using deep learning},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1049/ipr2.12419},
	doi = {10.1049/ipr2.12419},
	abstract = {Deep learning has been widely used for medical image segmentation and a large number of papers has been presented recording the success of deep learning in the field. A comprehensive thematic survey on medical image segmentation using deep learning techniques is presented. This paper makes two original contributions. Firstly, compared to traditional surveys that directly divide literatures of deep learning on medical image segmentation into many groups and introduce literatures in detail for each group, we classify currently popular literatures according to a multi-level structure from coarse to fine. Secondly, this paper focuses on supervised and weakly supervised learning approaches, without including unsupervised approaches since they have been introduced in many old surveys and they are not popular currently. For supervised learning approaches, we analyse literatures in three aspects: the selection of backbone networks, the design of network blocks, and the improvement of loss functions. For weakly supervised learning approaches, we investigate literature according to data augmentation, transfer learning, and interactive segmentation, separately. Compared to existing surveys, this survey classifies the literatures very differently from before and is more convenient for readers to understand the relevant rationale and will guide them to think of appropriate improvements in medical image segmentation based on deep learning approaches.},
	language = {en},
	number = {5},
	urldate = {2023-09-11},
	journal = {IET Image Processing},
	author = {Wang, Risheng and Lei, Tao and Cui, Ruixia and Zhang, Bingtao and Meng, Hongying and Nandi, Asoke K.},
	year = {2022},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1049/ipr2.12419},
	pages = {1243--1267},
	file = {Full Text PDF:/Users/farhanoktavian/Zotero/storage/9QC8XEX6/Wang et al. - 2022 - Medical image segmentation using deep learning A .pdf:application/pdf;Snapshot:/Users/farhanoktavian/Zotero/storage/7XLD8PV2/ipr2.html:text/html},
}

@article{maintz_survey_1998,
	title = {A survey of medical image registration},
	volume = {2},
	issn = {1361-8415},
	url = {https://www.sciencedirect.com/science/article/pii/S1361841501800268},
	doi = {10.1016/S1361-8415(01)80026-8},
	abstract = {The purpose of this paper is to present a survey of recent (published in 1993 or later) publications concerning medical image registration techniques. These publications will be classified according to a model based on nine salient criteria, the main dichotomy of which is extrinsic versus intrinsic methods. The statistics of the classification show definite trends in the evolving registration techniques, which will be discussed. At this moment, the bulk of interesting intrinsic methods is based on either segmented points or surfaces, or on techniques endeavouring to use the full information content of the images involved.},
	number = {1},
	urldate = {2023-09-11},
	journal = {Medical Image Analysis},
	author = {Maintz, J. B. Antoine and Viergever, Max A.},
	month = mar,
	year = {1998},
	keywords = {matching, registration},
	pages = {1--36},
	file = {ScienceDirect Full Text PDF:/Users/farhanoktavian/Zotero/storage/8M2YQBVZ/Maintz and Viergever - 1998 - A survey of medical image registration.pdf:application/pdf;ScienceDirect Snapshot:/Users/farhanoktavian/Zotero/storage/KIVCZ5EL/S1361841501800268.html:text/html},
}

@inproceedings{lucas_iterative_1981,
	address = {Vancouver, Canada},
	title = {An {Iterative} {Image} {Registration} {Technique} with an {Application} to {Stereo} {Vision}},
	volume = {2},
	url = {https://hal.science/hal-03697340},
	abstract = {Image registration finds a variety of applications in computer vision. Unfortunately, traditional image registration techniques tend to be costly. We present a new image registration technique that makes use of the spatial intensity gradient of the images to find a good match using a type of Newton-Raphson iteration. Our technique is faster because it examines far fewer potential matches between the images than existing techniques. Furthermore, this registration technique can be generalized to handle rotation, scaling and shearing. We show show our technique can be adapted for use in a stereo vision system.},
	urldate = {2023-09-11},
	booktitle = {{IJCAI}'81: 7th international joint conference on {Artificial} intelligence},
	author = {Lucas, Bruce D and Kanade, Takeo},
	month = aug,
	year = {1981},
	pages = {674--679},
	file = {HAL PDF Full Text:/Users/farhanoktavian/Zotero/storage/2FYXNLKJ/Lucas and Kanade - 1981 - An Iterative Image Registration Technique with an .pdf:application/pdf},
}

@inproceedings{pickering_new_2009,
	title = {A new multi-modal similarity measure for fast gradient-based {2D}-{3D} image registration},
	doi = {10.1109/IEMBS.2009.5335172},
	abstract = {2D-3D image registration has been adopted in many clinical applications such as image-guided surgery and the kinematic analysis of bones in knee and ankle joints. In this paper we propose a new single-plane 2D-3D registration algorithm which requires far less iteration than previous techniques. The new algorithm includes a new multi-modal similarity measure and a novel technique for the analytic calculation of the required gradients. Our experimental results show that, when compared to existing gradient and non-gradient based techniques, the proposed algorithm has a wider range of initial poses for which registration can be achieved and requires significantly fewer iterations to converge to the true 3D position of the anatomical structure.},
	booktitle = {2009 {Annual} {International} {Conference} of the {IEEE} {Engineering} in {Medicine} and {Biology} {Society}},
	author = {Pickering, Mark R. and Muhit, Abdullah A. and Scarvell, Jennie M. and Smith, Paul N.},
	month = sep,
	year = {2009},
	note = {ISSN: 1558-4615},
	keywords = {Algorithm design and analysis, Anatomical structure, Australia, Bones, Image registration, Joints, Kinematics, Knee, Least squares methods, Surgery},
	pages = {5821--5824},
	file = {IEEE Xplore Abstract Record:/Users/farhanoktavian/Zotero/storage/WYTS8DGE/5335172.html:text/html;IEEE Xplore Full Text PDF:/Users/farhanoktavian/Zotero/storage/X8DZBGK7/Pickering et al. - 2009 - A new multi-modal similarity measure for fast grad.pdf:application/pdf},
}

@misc{he_deep_2015,
	title = {Deep {Residual} {Learning} for {Image} {Recognition}},
	url = {http://arxiv.org/abs/1512.03385},
	doi = {10.48550/arXiv.1512.03385},
	abstract = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers---8x deeper than VGG nets but still having lower complexity. An ensemble of these residual nets achieves 3.57\% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28\% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC \& COCO 2015 competitions, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.},
	urldate = {2023-09-11},
	publisher = {arXiv},
	author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	month = dec,
	year = {2015},
	note = {arXiv:1512.03385 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:/Users/farhanoktavian/Zotero/storage/RXQD3JBE/He et al. - 2015 - Deep Residual Learning for Image Recognition.pdf:application/pdf;arXiv.org Snapshot:/Users/farhanoktavian/Zotero/storage/UJL3NZWG/1512.html:text/html},
}

@inproceedings{lowe_object_1999,
	title = {Object recognition from local scale-invariant features},
	volume = {2},
	doi = {10.1109/ICCV.1999.790410},
	abstract = {An object recognition system has been developed that uses a new class of local image features. The features are invariant to image scaling, translation, and rotation, and partially invariant to illumination changes and affine or 3D projection. These features share similar properties with neurons in inferior temporal cortex that are used for object recognition in primate vision. Features are efficiently detected through a staged filtering approach that identifies stable points in scale space. Image keys are created that allow for local geometric deformations by representing blurred image gradients in multiple orientation planes and at multiple scales. The keys are used as input to a nearest neighbor indexing method that identifies candidate object matches. Final verification of each match is achieved by finding a low residual least squares solution for the unknown model parameters. Experimental results show that robust object recognition can be achieved in cluttered partially occluded images with a computation time of under 2 seconds.},
	booktitle = {Proceedings of the {Seventh} {IEEE} {International} {Conference} on {Computer} {Vision}},
	author = {Lowe, D.G.},
	month = sep,
	year = {1999},
	keywords = {Computer science, Electrical capacitance tomography, Filters, Image recognition, Layout, Lighting, Neurons, Object recognition, Programmable logic arrays, Reactive power},
	pages = {1150--1157 vol.2},
	file = {IEEE Xplore Abstract Record:/Users/farhanoktavian/Zotero/storage/V86MQEIS/790410.html:text/html;IEEE Xplore Full Text PDF:/Users/farhanoktavian/Zotero/storage/LYKWKELJ/Lowe - 1999 - Object recognition from local scale-invariant feat.pdf:application/pdf},
}

@inproceedings{deng_imagenet_2009,
	title = {{ImageNet}: {A} large-scale hierarchical image database},
	shorttitle = {{ImageNet}},
	doi = {10.1109/CVPR.2009.5206848},
	abstract = {The explosion of image data on the Internet has the potential to foster more sophisticated and robust models and algorithms to index, retrieve, organize and interact with images and multimedia data. But exactly how such data can be harnessed and organized remains a critical problem. We introduce here a new database called “ImageNet”, a large-scale ontology of images built upon the backbone of the WordNet structure. ImageNet aims to populate the majority of the 80,000 synsets of WordNet with an average of 500–1000 clean and full resolution images. This will result in tens of millions of annotated images organized by the semantic hierarchy of WordNet. This paper offers a detailed analysis of ImageNet in its current state: 12 subtrees with 5247 synsets and 3.2 million images in total. We show that ImageNet is much larger in scale and diversity and much more accurate than the current image datasets. Constructing such a large-scale database is a challenging task. We describe the data collection scheme with Amazon Mechanical Turk. Lastly, we illustrate the usefulness of ImageNet through three simple applications in object recognition, image classification and automatic object clustering. We hope that the scale, accuracy, diversity and hierarchical structure of ImageNet can offer unparalleled opportunities to researchers in the computer vision community and beyond.},
	booktitle = {2009 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}},
	author = {Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
	month = jun,
	year = {2009},
	note = {ISSN: 1063-6919},
	keywords = {Explosions, Image databases, Image retrieval, Information retrieval, Internet, Large-scale systems, Multimedia databases, Ontologies, Robustness, Spine},
	pages = {248--255},
	file = {IEEE Xplore Abstract Record:/Users/farhanoktavian/Zotero/storage/4T498USU/5206848.html:text/html;IEEE Xplore Full Text PDF:/Users/farhanoktavian/Zotero/storage/U58YKJ3B/Deng et al. - 2009 - ImageNet A large-scale hierarchical image databas.pdf:application/pdf},
}

@misc{he_momentum_2020,
	title = {Momentum {Contrast} for {Unsupervised} {Visual} {Representation} {Learning}},
	url = {http://arxiv.org/abs/1911.05722},
	doi = {10.48550/arXiv.1911.05722},
	abstract = {We present Momentum Contrast (MoCo) for unsupervised visual representation learning. From a perspective on contrastive learning as dictionary look-up, we build a dynamic dictionary with a queue and a moving-averaged encoder. This enables building a large and consistent dictionary on-the-fly that facilitates contrastive unsupervised learning. MoCo provides competitive results under the common linear protocol on ImageNet classification. More importantly, the representations learned by MoCo transfer well to downstream tasks. MoCo can outperform its supervised pre-training counterpart in 7 detection/segmentation tasks on PASCAL VOC, COCO, and other datasets, sometimes surpassing it by large margins. This suggests that the gap between unsupervised and supervised representation learning has been largely closed in many vision tasks.},
	urldate = {2023-09-11},
	publisher = {arXiv},
	author = {He, Kaiming and Fan, Haoqi and Wu, Yuxin and Xie, Saining and Girshick, Ross},
	month = mar,
	year = {2020},
	note = {arXiv:1911.05722 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:/Users/farhanoktavian/Zotero/storage/SA2BUC2S/He et al. - 2020 - Momentum Contrast for Unsupervised Visual Represen.pdf:application/pdf;arXiv.org Snapshot:/Users/farhanoktavian/Zotero/storage/NICEVVAN/1911.html:text/html},
}

@misc{dosovitskiy_discriminative_2015,
	title = {Discriminative {Unsupervised} {Feature} {Learning} with {Exemplar} {Convolutional} {Neural} {Networks}},
	url = {http://arxiv.org/abs/1406.6909},
	doi = {10.48550/arXiv.1406.6909},
	abstract = {Deep convolutional networks have proven to be very successful in learning task specific features that allow for unprecedented performance on various computer vision tasks. Training of such networks follows mostly the supervised learning paradigm, where sufficiently many input-output pairs are required for training. Acquisition of large training sets is one of the key challenges, when approaching a new task. In this paper, we aim for generic feature learning and present an approach for training a convolutional network using only unlabeled data. To this end, we train the network to discriminate between a set of surrogate classes. Each surrogate class is formed by applying a variety of transformations to a randomly sampled 'seed' image patch. In contrast to supervised network training, the resulting feature representation is not class specific. It rather provides robustness to the transformations that have been applied during training. This generic feature representation allows for classification results that outperform the state of the art for unsupervised learning on several popular datasets (STL-10, CIFAR-10, Caltech-101, Caltech-256). While such generic features cannot compete with class specific features from supervised training on a classification task, we show that they are advantageous on geometric matching problems, where they also outperform the SIFT descriptor.},
	urldate = {2023-09-12},
	publisher = {arXiv},
	author = {Dosovitskiy, Alexey and Fischer, Philipp and Springenberg, Jost Tobias and Riedmiller, Martin and Brox, Thomas},
	month = jun,
	year = {2015},
	note = {arXiv:1406.6909 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
	file = {arXiv Fulltext PDF:/Users/farhanoktavian/Zotero/storage/M8W3QHFS/Dosovitskiy et al. - 2015 - Discriminative Unsupervised Feature Learning with .pdf:application/pdf;arXiv.org Snapshot:/Users/farhanoktavian/Zotero/storage/KZADLJ9P/1406.html:text/html},
}

@misc{kingma_adam_2017,
	title = {Adam: {A} {Method} for {Stochastic} {Optimization}},
	shorttitle = {Adam},
	url = {http://arxiv.org/abs/1412.6980},
	doi = {10.48550/arXiv.1412.6980},
	abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.},
	urldate = {2023-09-13},
	publisher = {arXiv},
	author = {Kingma, Diederik P. and Ba, Jimmy},
	month = jan,
	year = {2017},
	note = {arXiv:1412.6980 [cs]},
	keywords = {Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/farhanoktavian/Zotero/storage/S529MQ44/Kingma and Ba - 2017 - Adam A Method for Stochastic Optimization.pdf:application/pdf;arXiv.org Snapshot:/Users/farhanoktavian/Zotero/storage/MQLSDGY6/1412.html:text/html},
}

@article{wang_image_2004,
	title = {Image quality assessment: from error visibility to structural similarity},
	volume = {13},
	issn = {1941-0042},
	shorttitle = {Image quality assessment},
	doi = {10.1109/TIP.2003.819861},
	abstract = {Objective methods for assessing perceptual image quality traditionally attempted to quantify the visibility of errors (differences) between a distorted image and a reference image using a variety of known properties of the human visual system. Under the assumption that human visual perception is highly adapted for extracting structural information from a scene, we introduce an alternative complementary framework for quality assessment based on the degradation of structural information. As a specific example of this concept, we develop a structural similarity index and demonstrate its promise through a set of intuitive examples, as well as comparison to both subjective ratings and state-of-the-art objective methods on a database of images compressed with JPEG and JPEG2000. A MATLAB implementation of the proposed algorithm is available online at http://www.cns.nyu.edu//spl sim/lcv/ssim/.},
	number = {4},
	journal = {IEEE Transactions on Image Processing},
	author = {Wang, Zhou and Bovik, A.C. and Sheikh, H.R. and Simoncelli, E.P.},
	month = apr,
	year = {2004},
	note = {Conference Name: IEEE Transactions on Image Processing},
	keywords = {Data mining, Degradation, Humans, Image quality, Indexes, Layout, Quality assessment, Transform coding, Visual perception, Visual system},
	pages = {600--612},
	file = {IEEE Xplore Abstract Record:/Users/farhanoktavian/Zotero/storage/9CN9F7JC/1284395.html:text/html;IEEE Xplore Full Text PDF:/Users/farhanoktavian/Zotero/storage/I6VU2C65/Wang et al. - 2004 - Image quality assessment from error visibility to.pdf:application/pdf},
}

@article{fischler_random_1981,
	title = {Random sample consensus: a paradigm for model fitting with applications to image analysis and automated cartography},
	volume = {24},
	issn = {0001-0782},
	shorttitle = {Random sample consensus},
	url = {https://dl.acm.org/doi/10.1145/358669.358692},
	doi = {10.1145/358669.358692},
	abstract = {A new paradigm, Random Sample Consensus (RANSAC), for fitting a model to experimental data is introduced. RANSAC is capable of interpreting/smoothing data containing a significant percentage of gross errors, and is thus ideally suited for applications in automated image analysis where interpretation is based on the data provided by error-prone feature detectors. A major portion of this paper describes the application of RANSAC to the Location Determination Problem (LDP): Given an image depicting a set of landmarks with known locations, determine that point in space from which the image was obtained. In response to a RANSAC requirement, new results are derived on the minimum number of landmarks needed to obtain a solution, and algorithms are presented for computing these minimum-landmark solutions in closed form. These results provide the basis for an automatic system that can solve the LDP under difficult viewing},
	number = {6},
	urldate = {2023-09-14},
	journal = {Communications of the ACM},
	author = {Fischler, Martin A. and Bolles, Robert C.},
	month = jun,
	year = {1981},
	keywords = {automated cartography, camera calibration, image matching, location determination, model fitting, scene analysis},
	pages = {381--395},
	file = {Full Text PDF:/Users/farhanoktavian/Zotero/storage/HJZ3XLH2/Fischler and Bolles - 1981 - Random sample consensus a paradigm for model fitt.pdf:application/pdf},
}

@misc{tan_efficientnet_2020,
	title = {{EfficientNet}: {Rethinking} {Model} {Scaling} for {Convolutional} {Neural} {Networks}},
	shorttitle = {{EfficientNet}},
	url = {http://arxiv.org/abs/1905.11946},
	doi = {10.48550/arXiv.1905.11946},
	abstract = {Convolutional Neural Networks (ConvNets) are commonly developed at a fixed resource budget, and then scaled up for better accuracy if more resources are available. In this paper, we systematically study model scaling and identify that carefully balancing network depth, width, and resolution can lead to better performance. Based on this observation, we propose a new scaling method that uniformly scales all dimensions of depth/width/resolution using a simple yet highly effective compound coefficient. We demonstrate the effectiveness of this method on scaling up MobileNets and ResNet. To go even further, we use neural architecture search to design a new baseline network and scale it up to obtain a family of models, called EfficientNets, which achieve much better accuracy and efficiency than previous ConvNets. In particular, our EfficientNet-B7 achieves state-of-the-art 84.3\% top-1 accuracy on ImageNet, while being 8.4x smaller and 6.1x faster on inference than the best existing ConvNet. Our EfficientNets also transfer well and achieve state-of-the-art accuracy on CIFAR-100 (91.7\%), Flowers (98.8\%), and 3 other transfer learning datasets, with an order of magnitude fewer parameters. Source code is at https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet.},
	urldate = {2023-09-14},
	publisher = {arXiv},
	author = {Tan, Mingxing and Le, Quoc V.},
	month = sep,
	year = {2020},
	note = {arXiv:1905.11946 [cs, stat]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/farhanoktavian/Zotero/storage/MN5BHAND/Tan and Le - 2020 - EfficientNet Rethinking Model Scaling for Convolu.pdf:application/pdf;arXiv.org Snapshot:/Users/farhanoktavian/Zotero/storage/ZL4B297Z/1905.html:text/html},
}

@article{breiman_random_2001,
	title = {Random {Forests}},
	volume = {45},
	issn = {1573-0565},
	url = {https://doi.org/10.1023/A:1010933404324},
	doi = {10.1023/A:1010933404324},
	abstract = {Random forests are a combination of tree predictors such that each tree depends on the values of a random vector sampled independently and with the same distribution for all trees in the forest. The generalization error for forests converges a.s. to a limit as the number of trees in the forest becomes large. The generalization error of a forest of tree classifiers depends on the strength of the individual trees in the forest and the correlation between them. Using a random selection of features to split each node yields error rates that compare favorably to Adaboost (Y. Freund \& R. Schapire, Machine Learning: Proceedings of the Thirteenth International conference, ***, 148–156), but are more robust with respect to noise. Internal estimates monitor error, strength, and correlation and these are used to show the response to increasing the number of features used in the splitting. Internal estimates are also used to measure variable importance. These ideas are also applicable to regression.},
	language = {en},
	number = {1},
	urldate = {2023-09-14},
	journal = {Machine Learning},
	author = {Breiman, Leo},
	month = oct,
	year = {2001},
	keywords = {classification, ensemble, regression},
	pages = {5--32},
	file = {Full Text PDF:/Users/farhanoktavian/Zotero/storage/M9EG2EHB/Breiman - 2001 - Random Forests.pdf:application/pdf},
}

@misc{mathworks_autoencoders_nodate,
	title = {Autoencoders {Explained}},
	shorttitle = {What is an {Autoencoder}?},
	url = {https://uk.mathworks.com/discovery/autoencoder.html},
	abstract = {An autoencoder is a type of deep learning network that is trained to replicate its input to its output. Get started with videos and examples on data generation and others.},
	language = {en},
	urldate = {2023-09-15},
	journal = {MathWorks},
	author = {MathWorks},
	file = {Snapshot:/Users/farhanoktavian/Zotero/storage/6TJ62FEB/autoencoder.html:text/html},
}
